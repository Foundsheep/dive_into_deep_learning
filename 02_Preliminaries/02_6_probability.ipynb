{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c2ef73a8",
      "metadata": {
        "id": "c2ef73a8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a66c1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8a66c1f7",
        "outputId": "546751b8-1ff4-4d2a-83b0-914890ed29b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.23.5)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.31.0)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (9.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.3->d2l==1.0.3)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.5.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.12)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.15.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.21)\n",
            "Installing collected packages: tzdata, scipy, qtpy, pyparsing, jedi, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.7.2 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.5.1 qtpy-2.4.1 scipy-1.10.1 tzdata-2023.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad19fa4",
      "metadata": {
        "origin_pos": 1,
        "id": "0ad19fa4"
      },
      "source": [
        "# Probability and Statistics\n",
        ":label:`sec_prob`\n",
        "\n",
        "One way or another,\n",
        "machine learning is all about uncertainty.\n",
        "In supervised learning, we want to predict\n",
        "something unknown (the *target*)\n",
        "given something known (the *features*).\n",
        "Depending on our objective,\n",
        "we might attempt to predict\n",
        "the most likely value of the target.\n",
        "Or we might predict the value with the smallest\n",
        "expected distance from the target.\n",
        "And sometimes we wish not only\n",
        "to predict a specific value\n",
        "but to *quantify our uncertainty*.\n",
        "For example, given some features\n",
        "describing a patient,\n",
        "we might want to know *how likely* they are\n",
        "to suffer a heart attack in the next year.\n",
        "In unsupervised learning,\n",
        "we often care about uncertainty.\n",
        "To determine whether a set of measurements are anomalous,\n",
        "it helps to know how likely one is\n",
        "to observe values in a population of interest.\n",
        "Furthermore, in reinforcement learning,\n",
        "we wish to develop agents\n",
        "that act intelligently in various environments.\n",
        "This requires reasoning about\n",
        "how an environment might be expected to change\n",
        "and what rewards one might expect to encounter\n",
        "in response to each of the available actions.\n",
        "\n",
        "*Probability* is the mathematical field\n",
        "concerned with reasoning under uncertainty.\n",
        "Given a probabilistic model of some process,\n",
        "we can reason about the likelihood of various events.\n",
        "The use of probabilities to describe\n",
        "the frequencies of repeatable events\n",
        "(like coin tosses)\n",
        "is fairly uncontroversial.\n",
        "In fact, *frequentist* scholars adhere\n",
        "to an interpretation of probability\n",
        "that applies *only* to such repeatable events.\n",
        "By contrast *Bayesian* scholars\n",
        "use the language of probability more broadly\n",
        "to formalize reasoning under uncertainty.\n",
        "Bayesian probability is characterized\n",
        "by two unique features:\n",
        "(i) assigning degrees of belief\n",
        "to non-repeatable events,\n",
        "e.g., what is the *probability*\n",
        "that a dam will collapse?;\n",
        "and (ii) subjectivity. While Bayesian\n",
        "probability provides unambiguous rules\n",
        "for how one should update their beliefs\n",
        "in light of new evidence,\n",
        "it allows for different individuals\n",
        "to start off with different *prior* beliefs.\n",
        "*Statistics* helps us to reason backwards,\n",
        "starting off with collection and organization of data\n",
        "and backing out to what inferences\n",
        "we might draw about the process\n",
        "that generated the data.\n",
        "Whenever we analyze a dataset, hunting for patterns\n",
        "that we hope might characterize a broader population,\n",
        "we are employing statistical thinking.\n",
        "Many courses, majors, theses, careers, departments,\n",
        "companies, and institutions have been devoted\n",
        "to the study of probability and statistics.\n",
        "While this section only scratches the surface,\n",
        "we will provide the foundation\n",
        "that you need to begin building models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15d26295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:41.010215Z",
          "iopub.status.busy": "2023-08-18T19:35:41.009884Z",
          "iopub.status.idle": "2023-08-18T19:35:44.240517Z",
          "shell.execute_reply": "2023-08-18T19:35:44.239244Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "15d26295"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fa88a",
      "metadata": {
        "origin_pos": 6,
        "id": "390fa88a"
      },
      "source": [
        "## A Simple Example: Tossing Coins\n",
        "\n",
        "Imagine that we plan to toss a coin\n",
        "and want to quantify how likely\n",
        "we are to see heads (vs. tails).\n",
        "If the coin is *fair*,\n",
        "then both outcomes\n",
        "(heads and tails),\n",
        "are equally likely.\n",
        "Moreover if we plan to toss the coin $n$ times\n",
        "then the fraction of heads\n",
        "that we *expect* to see\n",
        "should exactly match\n",
        "the *expected* fraction of tails.\n",
        "One intuitive way to see this\n",
        "is by symmetry:\n",
        "for every possible outcome\n",
        "with $n_\\textrm{h}$ heads and $n_\\textrm{t} = (n - n_\\textrm{h})$ tails,\n",
        "there is an equally likely outcome\n",
        "with $n_\\textrm{t}$ heads and $n_\\textrm{h}$ tails.\n",
        "Note that this is only possible\n",
        "if on average we expect to see\n",
        "$1/2$ of tosses come up heads\n",
        "and $1/2$ come up tails.\n",
        "Of course, if you conduct this experiment\n",
        "many times with $n=1000000$ tosses each,\n",
        "you might never see a trial\n",
        "where $n_\\textrm{h} = n_\\textrm{t}$ exactly.\n",
        "\n",
        "\n",
        "Formally, the quantity $1/2$ is called a *probability*\n",
        "and here it captures the certainty with which\n",
        "any given toss will come up heads.\n",
        "Probabilities assign scores between $0$ and $1$\n",
        "to outcomes of interest, called *events*.\n",
        "Here the event of interest is $\\textrm{heads}$\n",
        "and we denote the corresponding probability $P(\\textrm{heads})$.\n",
        "A probability of $1$ indicates absolute certainty\n",
        "(imagine a trick coin where both sides were heads)\n",
        "and a probability of $0$ indicates impossibility\n",
        "(e.g., if both sides were tails).\n",
        "The frequencies $n_\\textrm{h}/n$ and $n_\\textrm{t}/n$ are not probabilities\n",
        "but rather *statistics*.\n",
        "Probabilities are *theoretical* quantities\n",
        "that underly the data generating process.\n",
        "Here, the probability $1/2$\n",
        "is a property of the coin itself.\n",
        "By contrast, statistics are *empirical* quantities\n",
        "that are computed as functions of the observed data.\n",
        "Our interests in probabilistic and statistical quantities\n",
        "are inextricably intertwined.\n",
        "We often design special statistics called *estimators*\n",
        "that, given a dataset, produce *estimates*\n",
        "of model parameters such as probabilities.\n",
        "Moreover, when those estimators satisfy\n",
        "a nice property called *consistency*,\n",
        "our estimates will converge\n",
        "to the corresponding probability.\n",
        "In turn, these inferred probabilities\n",
        "tell about the likely statistical properties\n",
        "of data from the same population\n",
        "that we might encounter in the future.\n",
        "\n",
        "Suppose that we stumbled upon a real coin\n",
        "for which we did not know\n",
        "the true $P(\\textrm{heads})$.\n",
        "To investigate this quantity\n",
        "with statistical methods,\n",
        "we need to (i) collect some data;\n",
        "and (ii) design an estimator.\n",
        "Data acquisition here is easy;\n",
        "we can toss the coin many times\n",
        "and record all the outcomes.\n",
        "Formally, drawing realizations\n",
        "from some underlying random process\n",
        "is called *sampling*.\n",
        "As you might have guessed,\n",
        "one natural estimator\n",
        "is the ratio of\n",
        "the number of observed *heads*\n",
        "to the total number of tosses.\n",
        "\n",
        "Now, suppose that the coin was in fact fair,\n",
        "i.e., $P(\\textrm{heads}) = 0.5$.\n",
        "To simulate tosses of a fair coin,\n",
        "we can invoke any random number generator.\n",
        "There are some easy ways to draw samples\n",
        "of an event with probability $0.5$.\n",
        "For example Python's `random.random`\n",
        "yields numbers in the interval $[0,1]$\n",
        "where the probability of lying\n",
        "in any sub-interval $[a, b] \\subset [0,1]$\n",
        "is equal to $b-a$.\n",
        "Thus we can get out `0` and `1` with probability `0.5` each\n",
        "by testing whether the returned float number is greater than `0.5`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a500e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.245216Z",
          "iopub.status.busy": "2023-08-18T19:35:44.244448Z",
          "iopub.status.idle": "2023-08-18T19:35:44.250559Z",
          "shell.execute_reply": "2023-08-18T19:35:44.249469Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a500e66",
        "outputId": "3cfa6d68-b6e2-442e-956b-986db6ed8261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [43, 57]\n"
          ]
        }
      ],
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096c1837",
      "metadata": {
        "origin_pos": 8,
        "id": "096c1837"
      },
      "source": [
        "More generally, we can simulate multiple draws\n",
        "from any variable with a finite number\n",
        "of possible outcomes\n",
        "(like the toss of a coin or roll of a die)\n",
        "by calling the multinomial function,\n",
        "setting the first argument\n",
        "to the number of draws\n",
        "and the second as a list of probabilities\n",
        "associated with each of the possible outcomes.\n",
        "To simulate ten tosses of a fair coin,\n",
        "we assign probability vector `[0.5, 0.5]`,\n",
        "interpreting index 0 as heads\n",
        "and index 1 as tails.\n",
        "The function returns a vector\n",
        "with length equal to the number\n",
        "of possible outcomes (here, 2),\n",
        "where the first component tells us\n",
        "the number of occurrences of heads\n",
        "and the second component tells us\n",
        "the number of occurrences of tails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b70ba754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.256289Z",
          "iopub.status.busy": "2023-08-18T19:35:44.255841Z",
          "iopub.status.idle": "2023-08-18T19:35:44.292323Z",
          "shell.execute_reply": "2023-08-18T19:35:44.291255Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b70ba754",
        "outputId": "b91715e2-7ea1-4a3e-fc2e-09948c95b565"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([40., 60.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fair_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZoy-FLB4Lyh",
        "outputId": "331724d6-aa06-4a46-c1f1-b755390c84ed"
      },
      "id": "aZoy-FLB4Lyh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5000, 0.5000])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Multinomial(100, fair_probs).sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djHMYr2m4OL1",
        "outputId": "56282ac1-6992-4ca7-b1c1-4355cff64876"
      },
      "id": "djHMYr2m4OL1",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([49., 51.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca81b0bc",
      "metadata": {
        "origin_pos": 13,
        "id": "ca81b0bc"
      },
      "source": [
        "Each time you run this sampling process,\n",
        "you will receive a new random value\n",
        "that may differ from the previous outcome.\n",
        "Dividing by the number of tosses\n",
        "gives us the *frequency*\n",
        "of each outcome in our data.\n",
        "Note that these frequencies,\n",
        "just like the probabilities\n",
        "that they are intended\n",
        "to estimate, sum to $1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d4157453",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.297194Z",
          "iopub.status.busy": "2023-08-18T19:35:44.296806Z",
          "iopub.status.idle": "2023-08-18T19:35:44.309679Z",
          "shell.execute_reply": "2023-08-18T19:35:44.308709Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4157453",
        "outputId": "6e42b57f-7e88-4569-ae41-522b3856add3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5500, 0.4500])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5135ef92",
      "metadata": {
        "origin_pos": 18,
        "id": "5135ef92"
      },
      "source": [
        "Here, even though our simulated coin is fair\n",
        "(we ourselves set the probabilities `[0.5, 0.5]`),\n",
        "the counts of heads and tails may not be identical.\n",
        "That is because we only drew a relatively small number of samples.\n",
        "If we did not implement the simulation ourselves,\n",
        "and only saw the outcome,\n",
        "how would we know if the coin were slightly unfair\n",
        "or if the possible deviation from $1/2$ was\n",
        "just an artifact of the small sample size?\n",
        "Let's see what happens when we simulate 10,000 tosses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3b639145",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.313908Z",
          "iopub.status.busy": "2023-08-18T19:35:44.313549Z",
          "iopub.status.idle": "2023-08-18T19:35:44.325094Z",
          "shell.execute_reply": "2023-08-18T19:35:44.324133Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b639145",
        "outputId": "4d907181-4f93-4c1c-f078-930f6cb7a86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5031, 0.4969])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8725b688",
      "metadata": {
        "origin_pos": 23,
        "id": "8725b688"
      },
      "source": [
        "In general, for averages of repeated events (like coin tosses),\n",
        "as the number of repetitions grows,\n",
        "our estimates are guaranteed to converge\n",
        "to the true underlying probabilities.\n",
        "The mathematical formulation of this phenomenon\n",
        "is called the *law of large numbers*\n",
        "and the *central limit theorem*\n",
        "tells us that in many situations,\n",
        "as the sample size $n$ grows,\n",
        "these errors should go down\n",
        "at a rate of $(1/\\sqrt{n})$.\n",
        "Let's get some more intuition by studying\n",
        "how our estimate evolves as we grow\n",
        "the number of tosses from 1 to 10,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fda7f94d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.329246Z",
          "iopub.status.busy": "2023-08-18T19:35:44.328647Z",
          "iopub.status.idle": "2023-08-18T19:35:44.675913Z",
          "shell.execute_reply": "2023-08-18T19:35:44.674711Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "fda7f94d",
        "outputId": "9fe24dfc-8fa3-47de-9333-8f0ee132377f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-12-27T06:06:12.122125</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m576a649f40\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m576a649f40\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m5dab90ff0d\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5dab90ff0d\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 16.02 \nL 55.217716 16.02 \nL 55.331864 116.819999 \nL 55.354693 104.22 \nL 55.468841 124.573845 \nL 55.491671 116.819999 \nL 55.697137 138.733046 \nL 55.719966 140.970002 \nL 55.742796 135.972001 \nL 55.788455 140.153333 \nL 55.902603 126.27 \nL 55.948262 130.161175 \nL 55.993921 133.619998 \nL 56.01675 130.441622 \nL 56.222216 115.72435 \nL 56.245046 117.356169 \nL 56.290705 113.220001 \nL 56.313535 114.804 \nL 56.427682 109.03091 \nL 56.450512 110.520002 \nL 56.633148 120.7575 \nL 56.678807 120.256364 \nL 56.701637 118.700595 \nL 56.747296 120.837393 \nL 56.792955 122.853801 \nL 56.815785 121.369998 \nL 56.884273 119.508001 \nL 56.907103 120.46737 \nL 57.089739 127.320001 \nL 57.135399 126.782791 \nL 57.203887 125.031236 \nL 57.272376 125.311305 \nL 57.318035 122.985955 \nL 57.386524 123.314846 \nL 57.432183 122.929089 \nL 57.500671 124.97294 \nL 57.637649 120.553334 \nL 57.660478 121.212662 \nL 57.683308 121.859999 \nL 57.706137 120.906487 \nL 57.728967 121.545002 \nL 57.751797 120.611152 \nL 57.797456 121.859999 \nL 57.820285 122.468275 \nL 57.843115 121.558461 \nL 57.865944 120.66407 \nL 57.911603 121.859999 \nL 57.934433 120.985291 \nL 57.980092 120.712683 \nL 58.025751 121.859999 \nL 58.276876 115.89353 \nL 58.345365 115.007052 \nL 58.459513 117.695001 \nL 58.573661 115.466982 \nL 58.59649 115.979999 \nL 58.642149 115.825261 \nL 58.801956 118.087924 \nL 58.824786 117.449998 \nL 58.870445 118.375558 \nL 58.893274 118.829816 \nL 58.938933 117.583634 \nL 59.075911 116.08316 \nL 59.09874 116.526977 \nL 59.144399 115.371723 \nL 59.212888 115.681016 \nL 59.304206 113.478562 \nL 59.349865 114.34131 \nL 59.395525 113.278376 \nL 59.441184 114.124811 \nL 59.532502 112.993823 \nL 59.555331 113.407502 \nL 59.578161 113.81689 \nL 59.62382 112.813846 \nL 59.737968 111.275999 \nL 59.760798 111.679704 \nL 59.783627 112.079404 \nL 59.829286 111.137647 \nL 59.874945 110.214174 \nL 59.920604 111.004615 \nL 59.943434 111.394163 \nL 59.989093 110.490142 \nL 60.034752 111.259439 \nL 60.080411 110.373486 \nL 60.1489 110.693393 \nL 60.263048 111.734799 \nL 60.194559 110.634545 \nL 60.308707 111.668002 \nL 60.422855 110.355654 \nL 60.445684 110.71091 \nL 60.719639 114.019999 \nL 60.742468 113.61836 \nL 60.879446 112.687201 \nL 60.925105 113.320002 \nL 60.993594 112.867058 \nL 61.1534 111.626108 \nL 61.17623 111.933308 \nL 61.244719 111.514735 \nL 61.564332 108.000002 \nL 61.632821 107.648269 \nL 61.769798 109.408235 \nL 61.906776 108.10678 \nL 61.929605 108.391622 \nL 61.952435 108.674545 \nL 62.020924 108.336001 \nL 62.043753 108.615349 \nL 62.112242 108.862103 \nL 62.20356 107.656365 \nL 62.249219 108.203227 \nL 62.294878 107.61231 \nL 62.454685 106.155423 \nL 62.477515 106.424998 \nL 62.591662 107.20523 \nL 62.614492 106.925524 \nL 62.682981 106.096596 \nL 62.72864 106.618187 \nL 62.979765 108.346316 \nL 63.048254 108.566085 \nL 63.093913 108.032681 \nL 63.116742 108.275171 \nL 63.162401 107.748002 \nL 63.185231 107.989231 \nL 63.390697 106.670001 \nL 63.504845 107.844659 \nL 63.550504 107.344249 \nL 63.618992 107.5573 \nL 63.664652 107.065164 \nL 63.687481 107.293996 \nL 63.75597 107.034893 \nL 63.938606 106.057498 \nL 64.029924 106.493193 \nL 63.984265 106.047978 \nL 64.052754 106.260618 \nL 64.212561 105.11091 \nL 64.23539 105.330831 \nL 64.25822 105.549649 \nL 64.326709 105.319749 \nL 64.349538 105.536417 \nL 64.395197 105.093267 \nL 64.440856 105.523447 \nL 64.463686 105.736955 \nL 64.509345 105.298237 \nL 64.555004 105.722188 \nL 64.600663 105.287797 \nL 64.646322 105.70771 \nL 64.669152 105.916155 \nL 64.737641 105.69351 \nL 64.76047 105.480003 \nL 64.806129 105.892035 \nL 64.828959 105.679574 \nL 64.920277 106.079016 \nL 64.874618 105.672708 \nL 64.943107 105.868599 \nL 64.965936 105.65916 \nL 65.011595 106.061762 \nL 65.034425 106.261664 \nL 65.080084 105.845804 \nL 65.102914 106.044829 \nL 65.194232 105.626377 \nL 65.217061 105.823635 \nL 65.239891 106.019999 \nL 65.28555 105.613681 \nL 65.354039 105.406545 \nL 65.376868 105.601206 \nL 65.422527 105.987931 \nL 65.468186 105.588957 \nL 65.491016 105.390794 \nL 65.536675 105.774186 \nL 65.559505 105.576923 \nL 65.764971 106.501037 \nL 65.947607 105.714917 \nL 66.038925 106.072944 \nL 65.993266 105.708609 \nL 66.084584 106.065189 \nL 66.244391 105.492988 \nL 66.267221 105.671851 \nL 66.33571 105.482579 \nL 66.358539 105.299998 \nL 66.404198 105.654145 \nL 66.449857 106.005426 \nL 66.518346 105.817184 \nL 66.723812 104.917232 \nL 66.746642 105.089824 \nL 66.792301 104.739841 \nL 66.83796 104.392602 \nL 66.883619 104.735788 \nL 67.043426 105.237691 \nL 67.180403 104.89072 \nL 67.203233 105.056814 \nL 67.248892 104.72019 \nL 67.294551 104.386104 \nL 67.34021 104.716436 \nL 67.477187 105.038183 \nL 67.522846 104.709092 \nL 67.568506 105.032153 \nL 67.636994 105.512308 \nL 67.682653 105.185693 \nL 67.751142 105.020361 \nL 67.773972 105.178695 \nL 67.796801 105.336457 \nL 67.84246 105.014594 \nL 68.047926 104.22 \nL 68.139244 104.841125 \nL 68.207733 104.683395 \nL 68.276222 104.834632 \nL 68.321881 104.526249 \nL 68.527347 105.275385 \nL 68.641495 104.817967 \nL 68.664324 104.966192 \nL 68.687154 105.113917 \nL 68.732813 104.81394 \nL 68.846961 104.367247 \nL 68.86979 104.514 \nL 68.89262 104.660269 \nL 68.938279 104.366269 \nL 68.961108 104.512055 \nL 69.006768 104.22 \nL 69.052427 104.51013 \nL 69.189404 104.794594 \nL 69.235063 104.506361 \nL 69.303552 104.647462 \nL 69.486188 105.486027 \nL 69.509018 105.343564 \nL 69.851461 103.808493 \nL 69.91995 103.946934 \nL 69.942779 103.811037 \nL 70.148245 103.144391 \nL 70.308052 103.554836 \nL 70.513518 102.907505 \nL 70.764643 104.090864 \nL 70.787473 103.962106 \nL 70.878791 103.707209 \nL 70.901621 103.835967 \nL 71.107087 104.472721 \nL 71.175575 104.597462 \nL 71.266894 104.094891 \nL 71.381041 104.716904 \nL 71.4267 104.467753 \nL 71.44953 104.3437 \nL 71.495189 104.59007 \nL 71.563678 104.465681 \nL 71.609337 104.710001 \nL 71.632166 104.58699 \nL 71.677826 104.829958 \nL 71.700655 104.707294 \nL 71.723485 104.828276 \nL 71.769144 104.583962 \nL 71.791973 104.704618 \nL 71.860462 104.340656 \nL 71.906121 104.580981 \nL 71.95178 104.820001 \nL 71.997439 104.579025 \nL 72.157246 104.22 \nL 72.202905 104.45646 \nL 72.248564 104.22 \nL 72.294224 103.984796 \nL 72.339883 104.22 \nL 72.362712 104.337129 \nL 72.408371 104.103176 \nL 72.591008 103.642021 \nL 72.613837 103.758224 \nL 72.659496 103.52914 \nL 72.682326 103.645028 \nL 72.750815 103.532725 \nL 72.773644 103.648014 \nL 72.97911 104.22 \nL 73.093258 103.882934 \nL 73.116088 103.995573 \nL 73.161747 104.22 \nL 73.207406 103.996709 \nL 73.230235 103.885489 \nL 73.275894 104.10878 \nL 73.549849 104.986957 \nL 73.937952 103.361605 \nL 73.960781 103.469818 \nL 74.120588 103.79494 \nL 74.394543 102.962989 \nL 74.463031 103.071832 \nL 74.485861 102.96894 \nL 74.600009 102.458073 \nL 74.645668 102.669 \nL 74.851134 103.196794 \nL 75.03377 102.800691 \nL 75.079429 103.006234 \nL 75.125088 102.807188 \nL 75.239236 102.714884 \nL 75.421873 103.126202 \nL 75.444702 103.028104 \nL 75.490361 103.228989 \nL 75.58168 103.430737 \nL 75.604509 103.33307 \nL 75.627339 103.235623 \nL 75.672998 103.434259 \nL 75.695827 103.337023 \nL 75.764316 103.242174 \nL 75.809975 103.439474 \nL 75.855634 103.246495 \nL 75.924123 103.346728 \nL 76.038271 103.448012 \nL 76.0611 103.352458 \nL 76.106759 103.546719 \nL 76.175248 103.836524 \nL 76.243737 103.742211 \nL 76.380714 103.555415 \nL 76.449203 103.462921 \nL 76.517691 103.748341 \nL 76.700328 103.378218 \nL 76.860135 103.848636 \nL 76.882964 103.756279 \nL 76.997112 103.48192 \nL 77.019942 103.574856 \nL 77.042771 103.667602 \nL 77.08843 103.485001 \nL 77.179748 103.30506 \nL 77.202578 103.397406 \nL 77.271067 103.308845 \nL 77.316726 103.492581 \nL 77.499362 103.137788 \nL 77.567851 103.231008 \nL 77.59068 103.142204 \nL 77.63634 102.965123 \nL 77.681999 103.146568 \nL 77.727658 103.327287 \nL 77.796146 103.240986 \nL 77.818976 103.153066 \nL 77.864635 103.332681 \nL 78.001612 103.690796 \nL 78.024442 103.603213 \nL 78.161419 103.081369 \nL 78.229908 103.172075 \nL 78.298397 103.262246 \nL 78.321226 103.176218 \nL 78.526692 102.581878 \nL 78.549522 102.669609 \nL 78.572351 102.757172 \nL 78.61801 102.588261 \nL 78.686499 102.507374 \nL 78.709329 102.59459 \nL 78.891965 102.94666 \nL 78.914795 102.863072 \nL 78.960454 103.034969 \nL 78.983283 102.951539 \nL 79.257238 103.634787 \nL 79.325727 103.553081 \nL 79.348556 103.636995 \nL 79.394215 103.80435 \nL 79.439874 103.639192 \nL 79.485534 103.474644 \nL 79.531193 103.641369 \nL 79.64534 103.726345 \nL 79.896466 103.161277 \nL 80.010613 103.24721 \nL 80.101932 103.089233 \nL 80.124761 103.170961 \nL 80.147591 103.252541 \nL 80.19325 103.093355 \nL 80.353057 102.70069 \nL 80.375886 102.781954 \nL 80.490034 102.867971 \nL 80.627011 102.717039 \nL 80.649841 102.797421 \nL 80.6955 102.642178 \nL 80.71833 102.722412 \nL 80.855307 102.573604 \nL 81.060773 102.975553 \nL 81.174921 102.903583 \nL 81.19775 102.982104 \nL 81.243409 102.829805 \nL 81.266239 102.908188 \nL 81.289069 102.832233 \nL 81.334728 102.988591 \nL 81.448875 103.07056 \nL 81.540194 102.921815 \nL 81.563023 102.999242 \nL 81.791319 103.463573 \nL 81.928296 103.015907 \nL 81.973955 103.168206 \nL 82.042444 103.095952 \nL 82.088103 103.247484 \nL 82.24791 102.881388 \nL 82.270739 102.956817 \nL 82.384887 103.184093 \nL 82.407717 103.11103 \nL 82.567524 102.750001 \nL 82.590353 102.824663 \nL 82.795819 103.199507 \nL 82.909967 102.985931 \nL 82.932797 103.059478 \nL 82.955626 103.132899 \nL 83.001285 102.989979 \nL 83.024115 102.918692 \nL 83.069774 103.065177 \nL 83.138263 103.284 \nL 83.183922 103.141763 \nL 83.366558 102.863072 \nL 83.480706 103.224194 \nL 83.549195 103.155642 \nL 83.617683 103.087414 \nL 83.640513 103.159059 \nL 83.663342 103.230577 \nL 83.709001 103.091042 \nL 83.731831 103.162444 \nL 83.868808 103.027157 \nL 83.891638 103.098223 \nL 83.937297 102.960003 \nL 83.960127 103.030942 \nL 84.028615 103.103543 \nL 84.074274 102.965975 \nL 84.188422 103.179088 \nL 84.211252 103.110567 \nL 84.439547 102.70643 \nL 84.462377 102.77635 \nL 84.508036 102.641326 \nL 84.622184 102.579071 \nL 84.781991 102.927945 \nL 84.80482 102.86099 \nL 84.918968 102.798514 \nL 85.010286 102.937828 \nL 85.033116 102.871378 \nL 85.192923 102.677337 \nL 85.215752 102.745533 \nL 85.261411 102.613926 \nL 85.466877 102.292494 \nL 85.558195 102.43082 \nL 85.581025 102.365947 \nL 85.740832 102.178026 \nL 85.923468 102.452069 \nL 85.969127 102.323932 \nL 86.014787 102.457305 \nL 86.174593 102.66124 \nL 86.197423 102.597482 \nL 86.243082 102.729478 \nL 86.311571 102.668095 \nL 86.380059 102.865059 \nL 86.402889 102.801574 \nL 86.448548 102.932413 \nL 86.471378 102.869012 \nL 86.654014 103.132689 \nL 86.836651 102.884605 \nL 86.973628 103.01699 \nL 87.064946 102.894162 \nL 87.087776 102.958194 \nL 87.179094 103.213438 \nL 87.247583 103.152813 \nL 87.430219 102.78433 \nL 87.453049 102.847721 \nL 87.498708 102.974239 \nL 87.544367 102.85159 \nL 87.704174 102.672627 \nL 87.88681 102.927472 \nL 88.000958 102.747951 \nL 88.023787 102.810269 \nL 88.092276 102.996697 \nL 88.137935 102.876236 \nL 88.320572 102.519171 \nL 88.343401 102.581048 \nL 88.434719 102.827691 \nL 88.480379 102.708691 \nL 88.503208 102.649317 \nL 88.548867 102.772123 \nL 88.571697 102.712823 \nL 88.731504 102.899998 \nL 88.799992 102.962568 \nL 88.91414 102.668442 \nL 88.93697 102.729131 \nL 88.982629 102.612033 \nL 89.165265 102.265263 \nL 89.188095 102.325772 \nL 89.256583 102.506807 \nL 89.302243 102.391108 \nL 89.576197 101.937449 \nL 89.781663 102.358261 \nL 89.804493 102.301347 \nL 89.827322 102.244507 \nL 89.872981 102.363161 \nL 89.895811 102.306394 \nL 90.055618 102.603769 \nL 90.078447 102.547139 \nL 90.261084 102.326308 \nL 90.420891 102.50627 \nL 90.603527 102.174125 \nL 90.626357 102.232237 \nL 90.900311 102.698334 \nL 91.060118 102.424585 \nL 91.082948 102.481793 \nL 91.105777 102.538928 \nL 91.151437 102.429138 \nL 91.174266 102.374348 \nL 91.219925 102.488396 \nL 91.242755 102.433669 \nL 91.356903 102.60625 \nL 91.379732 102.55165 \nL 91.562369 102.338694 \nL 91.767835 102.624367 \nL 91.859153 102.518572 \nL 91.881982 102.574476 \nL 92.01896 102.689891 \nL 92.041789 102.636227 \nL 92.087448 102.747268 \nL 92.110278 102.802699 \nL 92.155937 102.695559 \nL 92.315744 102.322639 \nL 92.384233 102.380246 \nL 92.407062 102.435446 \nL 92.452721 102.32961 \nL 92.49838 102.224036 \nL 92.566869 102.281539 \nL 92.726676 102.450639 \nL 92.749505 102.398131 \nL 92.795165 102.507374 \nL 92.817994 102.561901 \nL 92.863653 102.457064 \nL 92.932142 102.406942 \nL 92.954971 102.461332 \nL 92.977801 102.515649 \nL 93.02346 102.411316 \nL 93.04629 102.46557 \nL 93.206097 102.314122 \nL 93.251756 102.422156 \nL 93.297415 102.318685 \nL 93.388733 102.217854 \nL 93.411563 102.271697 \nL 93.617029 102.648739 \nL 93.639858 102.597334 \nL 93.662688 102.545983 \nL 93.708347 102.652461 \nL 93.731176 102.601172 \nL 93.754006 102.654322 \nL 93.799665 102.551913 \nL 93.936642 102.45392 \nL 94.164938 102.877382 \nL 94.187767 102.826556 \nL 94.438893 102.476515 \nL 94.461722 102.528771 \nL 94.507381 102.42836 \nL 94.667188 102.180696 \nL 94.690018 102.232826 \nL 94.712847 102.284893 \nL 94.758506 102.185396 \nL 94.826995 102.036577 \nL 94.872654 102.140532 \nL 94.941143 102.093481 \nL 95.055291 102.351995 \nL 95.283586 102.061433 \nL 95.443393 102.32 \nL 95.466223 102.271108 \nL 95.740177 101.887191 \nL 95.763007 101.938111 \nL 95.808666 101.841569 \nL 95.945643 101.652029 \nL 95.968473 101.702823 \nL 96.173939 101.96098 \nL 96.356575 101.775435 \nL 96.470723 101.928459 \nL 96.493553 101.880998 \nL 96.6077 101.838846 \nL 96.699019 101.941055 \nL 96.721848 101.893846 \nL 96.744678 101.84669 \nL 96.790337 101.94606 \nL 96.881655 102.144138 \nL 96.927314 102.049962 \nL 96.950144 102.002953 \nL 96.995803 102.101661 \nL 97.064291 102.153191 \nL 97.087121 102.106276 \nL 97.201269 101.968287 \nL 97.224098 102.017399 \nL 97.361076 102.119997 \nL 97.475223 101.982871 \nL 97.498053 102.031646 \nL 97.543712 102.12905 \nL 97.612201 102.084985 \nL 97.65786 101.992491 \nL 97.703519 102.089569 \nL 98.045962 102.623199 \nL 98.114451 102.672627 \nL 98.16011 102.580596 \nL 98.342747 102.7741 \nL 98.411235 102.636689 \nL 98.479724 102.685686 \nL 98.571042 102.781702 \nL 98.593872 102.736091 \nL 98.730849 102.555845 \nL 98.753679 102.602928 \nL 98.776508 102.649948 \nL 98.822167 102.559325 \nL 98.959145 102.380583 \nL 98.981974 102.427508 \nL 99.118951 102.524723 \nL 99.233099 102.483423 \nL 99.370077 102.579912 \nL 99.575543 102.360774 \nL 99.598372 102.407047 \nL 99.644031 102.31836 \nL 99.666861 102.364591 \nL 99.73535 102.41262 \nL 99.826668 102.235949 \nL 99.849497 102.282033 \nL 99.895156 102.193965 \nL 99.917986 102.239997 \nL 99.986475 102.108232 \nL 100.032134 102.200148 \nL 100.100622 102.158417 \nL 100.169111 102.295796 \nL 100.21477 102.208338 \nL 100.283259 102.256031 \nL 100.374577 102.349093 \nL 100.397407 102.305511 \nL 100.465895 102.352867 \nL 100.511554 102.265925 \nL 100.625702 102.315132 \nL 100.73985 102.098958 \nL 100.808339 102.146262 \nL 100.990975 102.330314 \nL 101.196441 102.119997 \nL 101.333418 102.213469 \nL 101.401907 102.259995 \nL 101.470396 102.132425 \nL 101.561714 102.223342 \nL 101.584544 102.180949 \nL 101.630203 102.096267 \nL 101.675862 102.184944 \nL 101.881328 102.409445 \nL 102.041135 102.286733 \nL 102.063964 102.330609 \nL 102.109623 102.246652 \nL 102.132453 102.290486 \nL 102.26943 102.210599 \nL 102.383578 102.428707 \nL 102.429237 102.345213 \nL 102.520555 102.26378 \nL 102.543385 102.307225 \nL 102.703192 102.440745 \nL 102.908658 102.237505 \nL 102.977146 102.366704 \nL 103.045635 102.327297 \nL 103.228272 102.166891 \nL 103.251101 102.209747 \nL 103.29676 102.127967 \nL 103.342419 102.046356 \nL 103.388078 102.131931 \nL 103.456567 102.176596 \nL 103.479397 102.135874 \nL 103.639204 102.018114 \nL 103.753351 102.147629 \nL 103.776181 102.107181 \nL 103.890329 102.070801 \nL 104.141454 102.369648 \nL 104.209942 102.413293 \nL 104.278431 102.292799 \nL 104.301261 102.334688 \nL 104.34692 102.254538 \nL 104.369749 102.296385 \nL 104.461068 102.218243 \nL 104.483897 102.259995 \nL 104.552386 102.303492 \nL 104.575215 102.263622 \nL 104.620874 102.183987 \nL 104.689363 102.227464 \nL 104.82634 102.31407 \nL 104.940488 102.116149 \nL 104.986147 102.198918 \nL 105.077466 102.283315 \nL 105.100295 102.243866 \nL 105.305761 102.05115 \nL 105.328591 102.092282 \nL 105.37425 102.013993 \nL 105.465568 101.937933 \nL 105.488398 101.97898 \nL 105.671034 102.146578 \nL 105.693864 102.107664 \nL 105.739523 102.189213 \nL 105.85367 102.233509 \nL 106.036307 102.003121 \nL 106.059136 102.043685 \nL 106.104796 102.124708 \nL 106.150455 102.047586 \nL 106.173284 102.009083 \nL 106.218943 102.089948 \nL 106.241773 102.051466 \nL 106.515728 102.376777 \nL 106.584216 102.26174 \nL 106.629875 102.341743 \nL 106.789682 102.464581 \nL 106.835341 102.388185 \nL 106.881 102.467683 \nL 107.132126 102.747415 \nL 107.177785 102.671271 \nL 107.223444 102.750001 \nL 107.40608 102.986436 \nL 107.42891 102.948437 \nL 107.520228 102.873733 \nL 107.543058 102.912762 \nL 107.794183 103.186858 \nL 107.885501 103.035853 \nL 107.93116 103.113206 \nL 108.273603 103.537456 \nL 108.43341 103.426089 \nL 108.616047 103.654859 \nL 108.638876 103.617438 \nL 108.775854 103.39359 \nL 108.821513 103.469366 \nL 108.912831 103.620508 \nL 108.95849 103.546141 \nL 109.072638 103.4355 \nL 109.095467 103.473172 \nL 109.141126 103.548423 \nL 109.186786 103.474434 \nL 109.369422 103.328338 \nL 109.46074 103.329842 \nL 109.552058 103.331335 \nL 109.620547 103.369438 \nL 109.643377 103.332828 \nL 109.780354 103.261299 \nL 109.96299 103.411496 \nL 110.168456 103.23146 \nL 110.236945 103.269259 \nL 110.259775 103.2331 \nL 110.442411 103.090632 \nL 110.670707 103.312966 \nL 110.762025 103.314459 \nL 110.784854 103.351039 \nL 110.830514 103.279394 \nL 110.944661 103.245213 \nL 111.081639 103.319632 \nL 111.446912 102.824548 \nL 111.469741 102.860874 \nL 111.720866 103.11616 \nL 111.766525 103.045894 \nL 111.812184 103.117948 \nL 112.086139 103.40628 \nL 112.177457 103.407584 \nL 112.291605 103.514966 \nL 112.314435 103.480006 \nL 112.405753 103.410823 \nL 112.428582 103.446319 \nL 112.474242 103.517216 \nL 112.519901 103.447549 \nL 112.634048 103.41404 \nL 112.679708 103.484706 \nL 112.725367 103.415323 \nL 113.04498 103.071832 \nL 113.181958 103.143971 \nL 113.318935 103.077247 \nL 113.433083 103.183168 \nL 113.455912 103.149028 \nL 113.615719 102.979685 \nL 113.638549 103.014614 \nL 113.707038 103.050425 \nL 113.729867 103.016496 \nL 113.775526 102.94871 \nL 113.821185 103.018367 \nL 113.958163 103.089675 \nL 114.003822 103.0221 \nL 114.049481 103.09142 \nL 114.209288 103.196794 \nL 114.254947 103.129429 \nL 114.300606 103.198382 \nL 114.437583 103.336645 \nL 114.460413 103.30302 \nL 114.506072 103.235855 \nL 114.551731 103.304429 \nL 114.711538 103.408341 \nL 114.825686 103.376147 \nL 115.031152 103.547235 \nL 115.190959 103.44838 \nL 115.327936 103.51708 \nL 115.442084 103.485001 \nL 115.556232 103.51974 \nL 115.579061 103.486662 \nL 115.62472 103.553838 \nL 115.693209 103.587862 \nL 115.716038 103.554836 \nL 115.875845 103.457085 \nL 116.035652 103.558338 \nL 116.1498 103.526553 \nL 116.17263 103.55982 \nL 116.218289 103.494348 \nL 116.537902 103.170004 \nL 116.606391 103.203944 \nL 116.629221 103.17156 \nL 116.697709 103.139996 \nL 116.720539 103.173116 \nL 116.903175 103.37192 \nL 116.926005 103.339631 \nL 117.222789 103.051792 \nL 117.336937 103.15111 \nL 117.382596 103.087152 \nL 117.496744 103.056923 \nL 117.656551 103.221019 \nL 117.70221 103.157345 \nL 117.839187 103.095405 \nL 118.044653 103.195165 \nL 118.067483 103.163517 \nL 118.113142 103.228274 \nL 118.295778 103.294934 \nL 118.409926 103.264769 \nL 118.432756 103.296943 \nL 118.501244 103.202556 \nL 118.843688 102.860159 \nL 119.003494 103.02129 \nL 119.049154 102.959098 \nL 119.140472 102.897948 \nL 119.163301 102.929879 \nL 119.323108 102.964482 \nL 119.460086 102.841875 \nL 119.482915 102.87367 \nL 119.802529 103.129577 \nL 119.985165 103.008379 \nL 120.144972 103.04235 \nL 120.373268 102.861179 \nL 120.555904 102.926567 \nL 120.692882 102.806337 \nL 120.715711 102.837554 \nL 120.738541 102.868749 \nL 120.807029 102.778117 \nL 121.012495 102.629708 \nL 121.126643 102.601929 \nL 121.263621 102.605283 \nL 121.469087 102.701404 \nL 121.560405 102.703497 \nL 121.583234 102.734335 \nL 121.720212 102.797904 \nL 121.743041 102.768149 \nL 121.880019 102.771125 \nL 122.108314 102.896402 \nL 122.199632 102.838121 \nL 122.245291 102.899104 \nL 122.33661 102.900902 \nL 122.359439 102.871378 \nL 122.496417 102.874122 \nL 122.633394 102.996245 \nL 122.679053 102.937418 \nL 122.975837 102.735155 \nL 123.089985 102.767297 \nL 123.112815 102.738141 \nL 123.36394 102.536909 \nL 123.386769 102.56699 \nL 123.523747 102.629214 \nL 123.546576 102.600299 \nL 123.706383 102.574697 \nL 123.889019 102.637678 \nL 124.003167 102.552533 \nL 124.048826 102.612107 \nL 124.185804 102.732012 \nL 124.231463 102.674677 \nL 124.459758 102.56352 \nL 124.642395 102.683814 \nL 124.665224 102.655352 \nL 124.733713 102.627941 \nL 124.779372 102.686842 \nL 125.007668 102.807188 \nL 125.213134 102.667591 \nL 125.235963 102.696831 \nL 125.39577 102.728973 \nL 125.578407 102.675645 \nL 125.715384 102.735723 \nL 125.738213 102.707671 \nL 125.806702 102.62362 \nL 125.875191 102.710604 \nL 126.012168 102.713527 \nL 126.171975 102.688556 \nL 126.308952 102.748109 \nL 126.331782 102.720288 \nL 126.537248 102.639959 \nL 126.834032 102.843189 \nL 126.971009 102.845818 \nL 127.176475 102.933633 \nL 127.359112 102.769526 \nL 127.404771 102.826198 \nL 127.655896 102.969918 \nL 127.838533 102.86222 \nL 127.861362 102.890356 \nL 127.998339 103.003448 \nL 128.043999 102.948952 \nL 128.295124 102.815631 \nL 128.317953 102.843599 \nL 128.386442 102.762377 \nL 128.523419 102.710194 \nL 128.546249 102.73811 \nL 128.660397 102.877413 \nL 128.728885 102.796538 \nL 128.843033 102.826072 \nL 128.934351 102.882397 \nL 128.98001 102.828659 \nL 129.208306 102.669767 \nL 129.231135 102.69743 \nL 129.413772 102.755427 \nL 129.573579 102.731507 \nL 129.779045 102.816578 \nL 129.870363 102.710468 \nL 129.938852 102.792637 \nL 130.03017 102.794382 \nL 130.052999 102.767928 \nL 130.075829 102.741485 \nL 130.144318 102.823412 \nL 130.53242 103.124509 \nL 130.669397 103.073157 \nL 130.692227 103.100168 \nL 130.829204 103.155421 \nL 130.852034 103.129135 \nL 131.0575 103.052486 \nL 131.240136 103.161172 \nL 131.262966 103.135034 \nL 131.422773 103.110903 \nL 131.445602 103.137631 \nL 131.514091 103.059478 \nL 131.605409 103.060855 \nL 131.628239 103.087541 \nL 131.696727 103.114867 \nL 131.742387 103.062937 \nL 131.902193 103.039101 \nL 131.970682 103.066375 \nL 132.016341 103.014656 \nL 132.130489 103.042603 \nL 132.221807 103.148534 \nL 132.290296 103.071159 \nL 132.58708 102.893489 \nL 132.701228 102.869475 \nL 132.815376 102.845523 \nL 132.838205 102.871851 \nL 133.043671 102.952979 \nL 133.249137 102.878948 \nL 133.500262 103.011785 \nL 133.728558 102.912762 \nL 133.911194 102.966942 \nL 134.071001 102.943958 \nL 134.162319 102.94543 \nL 134.185149 102.920322 \nL 134.459104 102.772428 \nL 134.64174 102.927787 \nL 134.687399 102.877886 \nL 134.710229 102.852947 \nL 134.778717 102.930006 \nL 134.892865 103.007632 \nL 134.938524 102.957837 \nL 135.121161 102.859981 \nL 135.14399 102.885541 \nL 135.349456 102.964303 \nL 135.554922 102.892364 \nL 135.828877 103.046661 \nL 136.011513 102.999494 \nL 136.034343 103.024739 \nL 136.102832 102.951118 \nL 136.285468 102.904319 \nL 136.490934 102.981935 \nL 136.513764 102.957521 \nL 136.582252 103.032782 \nL 136.6964 103.059152 \nL 136.71923 103.03478 \nL 136.924696 102.914613 \nL 136.947525 102.939595 \nL 137.312798 103.239451 \nL 137.335628 103.215226 \nL 137.449775 103.192147 \nL 137.472605 103.216898 \nL 137.655241 103.267934 \nL 137.883537 103.17319 \nL 138.089003 103.24863 \nL 138.203151 103.225719 \nL 138.22598 103.250238 \nL 138.362958 103.251836 \nL 138.385787 103.227906 \nL 138.454276 103.301254 \nL 138.659742 103.375863 \nL 138.796719 103.329095 \nL 138.819549 103.353404 \nL 139.025015 103.427572 \nL 139.27614 103.26234 \nL 139.298969 103.286544 \nL 139.435947 103.335845 \nL 139.458776 103.312199 \nL 139.664242 103.24291 \nL 139.77839 103.22043 \nL 139.846879 103.197457 \nL 139.892538 103.245549 \nL 140.029515 103.247116 \nL 140.30347 103.061034 \nL 140.3263 103.084986 \nL 140.508936 103.134602 \nL 140.714402 103.066596 \nL 140.874209 103.139229 \nL 140.897038 103.116034 \nL 141.056845 103.094638 \nL 141.170993 103.119546 \nL 141.193823 103.096436 \nL 141.239482 103.050236 \nL 141.30797 103.121302 \nL 141.536266 103.264096 \nL 141.559096 103.241038 \nL 141.718902 103.173043 \nL 141.741732 103.196584 \nL 141.83305 103.24413 \nL 141.878709 103.198203 \nL 142.038516 103.176901 \nL 142.152664 103.247715 \nL 142.198323 103.201957 \nL 142.38096 103.157902 \nL 142.540766 103.228989 \nL 142.563596 103.206205 \nL 142.723403 103.18506 \nL 142.769062 103.231576 \nL 142.837551 103.163433 \nL 143.043017 103.097161 \nL 143.179994 103.098907 \nL 143.202824 103.076332 \nL 143.271312 103.145779 \nL 143.294142 103.168911 \nL 143.36263 103.10123 \nL 143.476778 103.125476 \nL 143.727903 103.242279 \nL 143.88771 103.221335 \nL 144.207324 103.405849 \nL 144.344301 103.407101 \nL 144.43562 103.362814 \nL 144.686745 103.252751 \nL 144.846552 103.276924 \nL 145.120506 103.145485 \nL 145.234654 103.124488 \nL 145.41729 103.082084 \nL 145.622756 103.151446 \nL 145.736904 103.17503 \nL 145.9652 103.266367 \nL 146.147836 103.224016 \nL 146.307643 103.247852 \nL 146.49028 103.2057 \nL 146.832723 103.407195 \nL 146.946871 103.430148 \nL 147.106678 103.453426 \nL 147.312144 103.389573 \nL 147.540439 103.478818 \nL 147.677416 103.479922 \nL 147.860053 103.524829 \nL 147.974201 103.547382 \nL 148.179667 103.613811 \nL 148.270985 103.657666 \nL 148.54494 103.788705 \nL 148.659087 103.810764 \nL 148.796065 103.811363 \nL 148.978701 103.769233 \nL 149.206997 103.855975 \nL 149.366804 103.83522 \nL 149.640758 103.96422 \nL 149.891883 103.858614 \nL 150.120179 103.944306 \nL 150.371304 103.839279 \nL 150.622429 103.945757 \nL 150.713747 103.988171 \nL 150.896384 104.03068 \nL 151.010532 104.051919 \nL 151.284486 104.178101 \nL 151.421464 104.178164 \nL 151.649759 104.261742 \nL 151.786736 104.261684 \nL 151.923714 104.261626 \nL 152.174839 104.157724 \nL 152.380305 104.22 \nL 152.517282 104.22 \nL 152.65426 104.22 \nL 152.745578 104.261274 \nL 153.042362 104.405167 \nL 153.224998 104.363751 \nL 153.361976 104.363546 \nL 153.544612 104.322346 \nL 153.65876 104.30178 \nL 154.001203 104.118127 \nL 154.115351 104.097898 \nL 154.229499 104.118359 \nL 154.343647 104.098182 \nL 154.571942 104.017432 \nL 154.937215 104.22 \nL 155.119852 104.179709 \nL 155.348147 104.260201 \nL 155.462295 104.280231 \nL 155.576443 104.260107 \nL 155.781909 104.199991 \nL 155.918886 104.200012 \nL 156.101522 104.160153 \nL 156.261329 104.180161 \nL 156.466795 104.120609 \nL 156.695091 104.20017 \nL 156.809239 104.22 \nL 156.969046 104.239783 \nL 157.151682 104.200254 \nL 157.357148 104.259413 \nL 157.539784 104.22 \nL 157.722421 104.259271 \nL 157.859398 104.259218 \nL 158.110523 104.356927 \nL 158.224671 104.376315 \nL 158.361648 104.376105 \nL 158.544285 104.336871 \nL 158.704092 104.356139 \nL 158.932387 104.278217 \nL 159.115024 104.316857 \nL 159.32049 104.258666 \nL 159.571615 104.355008 \nL 159.708592 104.354835 \nL 159.84557 104.354656 \nL 159.982547 104.354483 \nL 160.096695 104.335142 \nL 160.210843 104.354188 \nL 160.370649 104.373124 \nL 160.644604 104.258183 \nL 160.8729 104.334301 \nL 160.987047 104.353205 \nL 161.124025 104.353032 \nL 161.420809 104.22 \nL 161.603445 104.257836 \nL 161.808911 104.201116 \nL 161.90023 104.163402 \nL 162.060037 104.144644 \nL 162.288332 104.22 \nL 162.607946 104.070067 \nL 162.813412 104.126465 \nL 162.90473 104.163927 \nL 163.018878 104.145317 \nL 163.270003 104.05235 \nL 163.40698 104.052571 \nL 163.612446 103.997182 \nL 163.749424 103.997455 \nL 163.909231 103.979266 \nL 164.046208 103.97957 \nL 164.183185 103.979875 \nL 164.342992 103.998675 \nL 164.662606 103.85219 \nL 164.890901 103.926368 \nL 165.119197 103.853725 \nL 165.256174 103.854177 \nL 165.393152 103.854629 \nL 165.530129 103.855082 \nL 165.689936 103.837397 \nL 165.98672 103.965607 \nL 166.192186 103.911669 \nL 166.397652 103.966554 \nL 166.694436 103.840835 \nL 166.922732 103.913688 \nL 167.151027 103.84238 \nL 167.379323 103.914929 \nL 167.630448 103.826094 \nL 167.790255 103.844525 \nL 168.018551 103.773912 \nL 168.246846 103.84605 \nL 168.406653 103.828785 \nL 168.589289 103.864923 \nL 168.931733 103.706694 \nL 169.114369 103.742863 \nL 169.251347 103.743431 \nL 169.411153 103.761725 \nL 169.57096 103.744766 \nL 169.844915 103.851254 \nL 170.09604 103.764459 \nL 170.278677 103.765185 \nL 170.438483 103.748341 \nL 170.666779 103.784142 \nL 170.849415 103.784836 \nL 171.100541 103.83788 \nL 171.374495 103.769475 \nL 171.671279 103.857037 \nL 171.876745 103.840425 \nL 172.1507 103.910166 \nL 172.401825 103.859298 \nL 172.65295 103.911491 \nL 172.904075 103.860833 \nL 173.086712 103.86139 \nL 173.429155 103.743241 \nL 173.634621 103.761063 \nL 173.908576 103.694298 \nL 174.091212 103.695097 \nL 174.387997 103.61196 \nL 174.570633 103.612886 \nL 174.798929 103.580386 \nL 174.935906 103.547487 \nL 175.187031 103.498564 \nL 175.438156 103.550294 \nL 175.666452 103.518142 \nL 175.940406 103.586432 \nL 176.237191 103.50482 \nL 176.374168 103.472405 \nL 176.488316 103.522894 \nL 176.739441 103.574025 \nL 176.990566 103.525775 \nL 177.150373 103.510172 \nL 177.333009 103.511234 \nL 177.515646 103.512296 \nL 177.766771 103.464466 \nL 177.995066 103.498659 \nL 178.200532 103.483497 \nL 178.405998 103.501066 \nL 178.634294 103.469776 \nL 178.908249 103.536531 \nL 179.182203 103.473088 \nL 179.319181 103.441482 \nL 179.570306 103.394494 \nL 179.912749 103.509751 \nL 180.209533 103.430915 \nL 180.437829 103.464508 \nL 180.574806 103.497439 \nL 180.757443 103.49849 \nL 180.940079 103.499542 \nL 181.259693 103.597188 \nL 181.579307 103.50319 \nL 181.830432 103.552302 \nL 181.967409 103.584781 \nL 182.195705 103.617628 \nL 182.401171 103.602771 \nL 182.538148 103.571817 \nL 182.92625 103.431935 \nL 183.131716 103.448937 \nL 183.382842 103.403336 \nL 183.633967 103.451954 \nL 183.793774 103.468567 \nL 183.95358 103.453857 \nL 184.204706 103.40853 \nL 184.387342 103.409687 \nL 184.684126 103.333806 \nL 184.889592 103.350734 \nL 185.209206 103.259953 \nL 185.369013 103.245675 \nL 185.688627 103.155494 \nL 185.962581 103.219305 \nL 186.122388 103.235897 \nL 186.282195 103.221745 \nL 186.53332 103.177669 \nL 186.693127 103.163622 \nL 186.989911 103.089622 \nL 187.469332 103.29158 \nL 187.651968 103.292863 \nL 187.857434 103.309465 \nL 188.040071 103.310727 \nL 188.314026 103.373087 \nL 188.451003 103.404178 \nL 188.679298 103.435731 \nL 188.976083 103.362226 \nL 189.455503 103.56022 \nL 189.729458 103.501708 \nL 189.866435 103.472541 \nL 190.094731 103.443964 \nL 190.277367 103.445004 \nL 190.460004 103.446056 \nL 190.802447 103.551934 \nL 190.939424 103.582268 \nL 191.099231 103.5682 \nL 191.441675 103.466411 \nL 191.6928 103.512043 \nL 191.943925 103.469177 \nL 192.149391 103.485001 \nL 192.377686 103.456875 \nL 192.605982 103.48744 \nL 192.879937 103.430411 \nL 193.016914 103.40198 \nL 193.24521 103.37417 \nL 193.427846 103.375284 \nL 193.72463 103.304429 \nL 193.838778 103.261625 \nL 193.975755 103.29158 \nL 194.204051 103.322072 \nL 194.614983 103.180318 \nL 194.820449 103.196258 \nL 194.957426 103.226077 \nL 195.117233 103.212818 \nL 195.322699 103.199928 \nL 195.550995 103.230282 \nL 195.77929 103.20324 \nL 196.053245 103.262393 \nL 196.372859 103.178994 \nL 196.555495 103.18034 \nL 196.760961 103.167628 \nL 196.989257 103.19772 \nL 197.126234 103.227075 \nL 197.3317 103.242679 \nL 197.582825 103.201978 \nL 197.788291 103.217571 \nL 198.062246 103.163117 \nL 198.3362 103.221408 \nL 198.541666 103.208791 \nL 199.043917 103.408257 \nL 199.272212 103.381593 \nL 199.614656 103.481163 \nL 200.025588 103.344257 \nL 200.276713 103.387397 \nL 200.573497 103.319864 \nL 200.801793 103.348925 \nL 200.984429 103.350019 \nL 201.235554 103.392864 \nL 201.44102 103.380258 \nL 201.623657 103.381309 \nL 202.034589 103.246548 \nL 202.194395 103.23391 \nL 202.377032 103.23514 \nL 202.582498 103.250165 \nL 203.016259 103.103196 \nL 203.176066 103.0908 \nL 203.313044 103.119031 \nL 203.632657 103.202777 \nL 203.769635 103.230818 \nL 203.975101 103.245717 \nL 204.363203 103.12678 \nL 204.54584 103.128115 \nL 204.728476 103.129451 \nL 204.933942 103.144391 \nL 205.116579 103.145706 \nL 205.230726 103.106267 \nL 205.57317 103.015087 \nL 205.847124 103.070728 \nL 206.029761 103.072116 \nL 206.212397 103.073504 \nL 206.395034 103.074892 \nL 206.668988 103.130123 \nL 207.057091 103.013594 \nL 207.308216 103.055293 \nL 207.445193 103.082788 \nL 207.719148 103.137631 \nL 207.924614 103.125907 \nL 208.221398 103.193808 \nL 208.426864 103.182043 \nL 208.677989 103.223091 \nL 208.860626 103.224279 \nL 209.111751 103.265148 \nL 209.271558 103.279205 \nL 209.65966 103.398868 \nL 209.796637 103.425637 \nL 209.933615 103.400319 \nL 210.207569 103.349819 \nL 210.413035 103.36394 \nL 210.641331 103.339294 \nL 210.823967 103.340324 \nL 210.938115 103.379753 \nL 211.18924 103.419823 \nL 211.371877 103.420759 \nL 211.623002 103.46065 \nL 211.896957 103.410591 \nL 212.079593 103.411527 \nL 212.376377 103.34902 \nL 212.604673 103.375863 \nL 212.878627 103.326256 \nL 213.015605 103.301516 \nL 213.449366 103.164095 \nL 213.700491 103.178468 \nL 213.905957 103.167134 \nL 214.248401 103.23269 \nL 214.408208 103.271614 \nL 214.750651 103.336739 \nL 214.933287 103.362951 \nL 215.230072 103.402285 \nL 215.549685 103.353699 \nL 215.709492 103.31693 \nL 215.869299 103.355412 \nL 216.120424 103.369281 \nL 216.34872 103.370479 \nL 216.554186 103.359082 \nL 216.736822 103.384989 \nL 216.965118 103.386167 \nL 217.261902 103.350418 \nL 217.444539 103.326582 \nL 217.718493 103.303314 \nL 217.923959 103.292096 \nL 218.289232 103.220115 \nL 218.608846 103.271351 \nL 218.859971 103.2605 \nL 219.088267 103.261836 \nL 219.385051 103.226781 \nL 219.567687 103.203387 \nL 219.841642 103.180623 \nL 220.275404 103.293115 \nL 220.526529 103.282349 \nL 220.891802 103.357316 \nL 221.074438 103.382539 \nL 221.302734 103.383696 \nL 221.553859 103.372856 \nL 221.850643 103.410602 \nL 222.170257 103.363918 \nL 222.5127 103.425837 \nL 222.786655 103.403116 \nL 222.992121 103.392118 \nL 223.266075 103.369502 \nL 223.677007 103.467179 \nL 223.882473 103.480027 \nL 224.179258 103.517069 \nL 224.407553 103.518015 \nL 224.59019 103.495 \nL 224.864144 103.472447 \nL 225.06961 103.461491 \nL 225.412054 103.403883 \nL 225.640349 103.404977 \nL 225.822986 103.429443 \nL 226.211088 103.513642 \nL 226.530702 103.467957 \nL 226.827486 103.504452 \nL 227.12427 103.470554 \nL 227.398225 103.495136 \nL 227.64935 103.484517 \nL 227.968964 103.532483 \nL 228.425555 103.418077 \nL 228.767998 103.477651 \nL 229.019123 103.467147 \nL 229.224589 103.456465 \nL 229.589862 103.388795 \nL 229.909476 103.436414 \nL 230.137772 103.437434 \nL 230.388897 103.450041 \nL 230.617192 103.45105 \nL 230.891147 103.475159 \nL 231.187931 103.442103 \nL 231.324908 103.396986 \nL 231.598863 103.375432 \nL 232.032625 103.479975 \nL 232.329409 103.447118 \nL 232.649023 103.493885 \nL 232.831659 103.517301 \nL 233.31108 103.643524 \nL 233.585034 103.621844 \nL 234.018796 103.724621 \nL 234.452558 103.624735 \nL 234.703683 103.636785 \nL 235.023296 103.593035 \nL 235.479888 103.706305 \nL 235.685354 103.718039 \nL 236.027797 103.774658 \nL 236.256092 103.775215 \nL 236.644195 103.853841 \nL 237.055127 103.766099 \nL 237.214934 103.733316 \nL 237.4204 103.744913 \nL 237.648695 103.745513 \nL 237.94548 103.713234 \nL 238.173775 103.713865 \nL 238.493389 103.670809 \nL 238.721684 103.671492 \nL 238.904321 103.693961 \nL 239.155446 103.705621 \nL 239.543549 103.630255 \nL 239.771844 103.630981 \nL 240.045799 103.610068 \nL 240.251265 103.599869 \nL 240.570879 103.557497 \nL 240.822004 103.569241 \nL 241.02747 103.580796 \nL 241.255765 103.581574 \nL 241.666697 103.496608 \nL 242.03197 103.56268 \nL 242.283095 103.552797 \nL 242.465732 103.531947 \nL 242.694027 103.532788 \nL 242.922323 103.533619 \nL 243.150618 103.534449 \nL 243.333255 103.513715 \nL 243.58438 103.503968 \nL 243.789846 103.494075 \nL 244.063801 103.473803 \nL 244.383414 103.517637 \nL 244.61171 103.518478 \nL 244.817176 103.508626 \nL 245.022642 103.520003 \nL 245.365085 103.574193 \nL 245.63904 103.553985 \nL 245.958654 103.597314 \nL 246.346756 103.52485 \nL 246.64354 103.557475 \nL 246.894665 103.547844 \nL 247.214279 103.5909 \nL 247.579552 103.529297 \nL 247.899166 103.572238 \nL 248.036143 103.614463 \nL 248.21878 103.59417 \nL 248.606882 103.522558 \nL 248.766689 103.49193 \nL 248.972155 103.503096 \nL 249.24611 103.52486 \nL 249.428746 103.546246 \nL 249.702701 103.567895 \nL 249.885337 103.589186 \nL 250.182121 103.621129 \nL 250.456076 103.601341 \nL 250.821349 103.664248 \nL 251.118133 103.634261 \nL 251.414917 103.66593 \nL 251.688872 103.646205 \nL 252.099804 103.729205 \nL 252.282441 103.750086 \nL 252.465077 103.730109 \nL 252.670543 103.740823 \nL 252.944498 103.761841 \nL 253.309771 103.70171 \nL 253.652214 103.753335 \nL 253.880509 103.753871 \nL 254.131635 103.744335 \nL 254.519737 103.674562 \nL 254.86218 103.705748 \nL 255.181794 103.686433 \nL 255.547067 103.727596 \nL 255.706874 103.778201 \nL 256.003658 103.788873 \nL 256.209124 103.819365 \nL 256.460249 103.80986 \nL 256.757033 103.800471 \nL 257.099477 103.831099 \nL 257.46475 103.791986 \nL 257.715875 103.782575 \nL 257.967 103.793047 \nL 258.332273 103.833464 \nL 258.697546 103.794583 \nL 258.9715 103.79515 \nL 259.154137 103.83502 \nL 259.565069 103.894899 \nL 259.907512 103.865943 \nL 260.067319 103.817083 \nL 260.295615 103.837165 \nL 260.683717 103.886877 \nL 260.957672 103.887318 \nL 261.231626 103.88776 \nL 261.57407 103.859045 \nL 261.802365 103.839952 \nL 262.258956 103.763008 \nL 262.829695 103.890315 \nL 262.989502 103.939017 \nL 263.423264 104.007286 \nL 263.697218 104.007559 \nL 264.222298 104.114048 \nL 264.541912 104.094975 \nL 264.884355 104.123984 \nL 265.340946 104.047545 \nL 265.820367 104.133972 \nL 266.071492 104.143624 \nL 266.345447 104.143719 \nL 266.665061 104.124793 \nL 266.916186 104.115394 \nL 267.19014 104.11553 \nL 267.395606 104.087173 \nL 267.646732 104.096804 \nL 268.012004 104.134856 \nL 268.400107 104.087794 \nL 268.76538 104.125729 \nL 269.176312 104.069457 \nL 269.495926 104.088467 \nL 269.76988 104.088635 \nL 270.089494 104.107571 \nL 270.31779 104.126413 \nL 270.637403 104.145244 \nL 270.957017 104.126686 \nL 271.208142 104.117475 \nL 271.482097 104.117602 \nL 271.84737 104.154948 \nL 272.144154 104.145759 \nL 272.440938 104.155127 \nL 272.646404 104.182969 \nL 272.988848 104.210758 \nL 273.308461 104.192305 \nL 273.513927 104.164663 \nL 273.856371 104.137127 \nL 274.039007 104.1004 \nL 274.244473 104.128084 \nL 274.586916 104.155758 \nL 274.792382 104.183326 \nL 275.089167 104.192537 \nL 275.385951 104.183421 \nL 275.774053 104.229126 \nL 275.95669 104.2656 \nL 276.43611 104.347407 \nL 276.755724 104.329043 \nL 277.212315 104.401371 \nL 277.5091 104.392071 \nL 277.805884 104.400887 \nL 278.125498 104.382566 \nL 278.353793 104.364356 \nL 278.650577 104.35515 \nL 278.993021 104.381935 \nL 279.289805 104.372735 \nL 279.586589 104.381504 \nL 279.906203 104.363357 \nL 280.180158 104.363183 \nL 280.385624 104.389874 \nL 280.659578 104.389669 \nL 280.933533 104.389464 \nL 281.230317 104.398148 \nL 281.481442 104.406844 \nL 281.801056 104.42435 \nL 282.257647 104.353005 \nL 282.485943 104.335157 \nL 282.874045 104.290745 \nL 283.239318 104.325947 \nL 283.467614 104.308199 \nL 283.467614 104.308199 \n\" clip-path=\"url(#p3da5497770)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 192.42 \nL 55.217716 192.42 \nL 55.331864 91.619995 \nL 55.354693 104.22 \nL 55.468841 83.86615 \nL 55.491671 91.619995 \nL 55.697137 69.706954 \nL 55.719966 67.470004 \nL 55.742796 72.467999 \nL 55.788455 68.286667 \nL 55.902603 82.17 \nL 55.948262 78.27882 \nL 55.993921 74.819996 \nL 56.01675 77.998383 \nL 56.222216 92.715655 \nL 56.245046 91.083831 \nL 56.290705 95.220004 \nL 56.313535 93.636 \nL 56.427682 99.409095 \nL 56.450512 97.920003 \nL 56.633148 87.6825 \nL 56.678807 88.183641 \nL 56.701637 89.739405 \nL 56.747296 87.602613 \nL 56.792955 85.586199 \nL 56.815785 87.070002 \nL 56.884273 88.932004 \nL 56.907103 87.97263 \nL 57.089739 81.120004 \nL 57.135399 81.657209 \nL 57.203887 83.408769 \nL 57.272376 83.128701 \nL 57.318035 85.454045 \nL 57.386524 85.125159 \nL 57.432183 85.510906 \nL 57.500671 83.46706 \nL 57.637649 87.886666 \nL 57.660478 87.227338 \nL 57.683308 86.579996 \nL 57.706137 87.533513 \nL 57.728967 86.895003 \nL 57.751797 87.828848 \nL 57.797456 86.579996 \nL 57.820285 85.971725 \nL 57.843115 86.881534 \nL 57.865944 87.77593 \nL 57.911603 86.579996 \nL 57.934433 87.454709 \nL 57.980092 87.727322 \nL 58.025751 86.579996 \nL 58.276876 92.54647 \nL 58.345365 93.432948 \nL 58.459513 90.744999 \nL 58.573661 92.973023 \nL 58.59649 92.460001 \nL 58.642149 92.614739 \nL 58.801956 90.35207 \nL 58.824786 90.990002 \nL 58.870445 90.064442 \nL 58.893274 89.610184 \nL 58.938933 90.856366 \nL 59.075911 92.356845 \nL 59.09874 91.913028 \nL 59.144399 93.068272 \nL 59.212888 92.758984 \nL 59.304206 94.961438 \nL 59.349865 94.09869 \nL 59.395525 95.161619 \nL 59.441184 94.315189 \nL 59.532502 95.446177 \nL 59.555331 95.032504 \nL 59.578161 94.62311 \nL 59.62382 95.626149 \nL 59.737968 97.163996 \nL 59.760798 96.760301 \nL 59.783627 96.360591 \nL 59.829286 97.302353 \nL 59.874945 98.225821 \nL 59.920604 97.43538 \nL 59.943434 97.045837 \nL 59.989093 97.949853 \nL 60.034752 97.180567 \nL 60.080411 98.066509 \nL 60.1489 97.746602 \nL 60.263048 96.705207 \nL 60.194559 97.80545 \nL 60.308707 96.772004 \nL 60.422855 98.084351 \nL 60.445684 97.729096 \nL 60.719639 94.419995 \nL 60.742468 94.82164 \nL 60.879446 95.752804 \nL 60.925105 95.120003 \nL 60.993594 95.572936 \nL 61.1534 96.813892 \nL 61.17623 96.506687 \nL 61.244719 96.925259 \nL 61.564332 100.439998 \nL 61.632821 100.791731 \nL 61.769798 99.03176 \nL 61.906776 100.333225 \nL 61.929605 100.048383 \nL 61.952435 99.765455 \nL 62.020924 100.104004 \nL 62.043753 99.824651 \nL 62.112242 99.577891 \nL 62.20356 100.783635 \nL 62.249219 100.236778 \nL 62.294878 100.82769 \nL 62.454685 102.284577 \nL 62.477515 102.015002 \nL 62.591662 101.23477 \nL 62.614492 101.514481 \nL 62.682981 102.343404 \nL 62.72864 101.821813 \nL 62.979765 100.093689 \nL 63.048254 99.87391 \nL 63.093913 100.407319 \nL 63.116742 100.164829 \nL 63.162401 100.692003 \nL 63.185231 100.450764 \nL 63.390697 101.769999 \nL 63.504845 100.595346 \nL 63.550504 101.095751 \nL 63.618992 100.8827 \nL 63.664652 101.374841 \nL 63.687481 101.146009 \nL 63.75597 101.405101 \nL 63.938606 102.382496 \nL 64.029924 101.946807 \nL 63.984265 102.392022 \nL 64.052754 102.179382 \nL 64.212561 103.329095 \nL 64.23539 103.109169 \nL 64.25822 102.890356 \nL 64.326709 103.120251 \nL 64.349538 102.903583 \nL 64.395197 103.346728 \nL 64.440856 102.916547 \nL 64.463686 102.703045 \nL 64.509345 103.141763 \nL 64.555004 102.717807 \nL 64.600663 103.152203 \nL 64.646322 102.732285 \nL 64.669152 102.52385 \nL 64.737641 102.74649 \nL 64.76047 102.960003 \nL 64.806129 102.547959 \nL 64.828959 102.760421 \nL 64.920277 102.360984 \nL 64.874618 102.767297 \nL 64.943107 102.571406 \nL 64.965936 102.78084 \nL 65.011595 102.378238 \nL 65.034425 102.178331 \nL 65.080084 102.594191 \nL 65.102914 102.395177 \nL 65.194232 102.813623 \nL 65.217061 102.616365 \nL 65.239891 102.420001 \nL 65.28555 102.826324 \nL 65.354039 103.033455 \nL 65.376868 102.838794 \nL 65.422527 102.452069 \nL 65.468186 102.851043 \nL 65.491016 103.049206 \nL 65.536675 102.665814 \nL 65.559505 102.863072 \nL 65.764971 101.938963 \nL 65.947607 102.725083 \nL 66.038925 102.367062 \nL 65.993266 102.731391 \nL 66.084584 102.374811 \nL 66.244391 102.947007 \nL 66.267221 102.768149 \nL 66.33571 102.957427 \nL 66.358539 103.139996 \nL 66.404198 102.785855 \nL 66.449857 102.434574 \nL 66.518346 102.622821 \nL 66.723812 103.522768 \nL 66.746642 103.350176 \nL 66.792301 103.700154 \nL 66.83796 104.047398 \nL 66.883619 103.704212 \nL 67.043426 103.202304 \nL 67.180403 103.549274 \nL 67.203233 103.383191 \nL 67.248892 103.719816 \nL 67.294551 104.053896 \nL 67.34021 103.723569 \nL 67.477187 103.401822 \nL 67.522846 103.730908 \nL 67.568506 103.407847 \nL 67.636994 102.927692 \nL 67.682653 103.254307 \nL 67.751142 103.419634 \nL 67.773972 103.261299 \nL 67.796801 103.103543 \nL 67.84246 103.425406 \nL 68.047926 104.22 \nL 68.139244 103.59887 \nL 68.207733 103.756605 \nL 68.276222 103.605368 \nL 68.321881 103.913751 \nL 68.527347 103.16461 \nL 68.641495 103.622033 \nL 68.664324 103.473803 \nL 68.687154 103.326078 \nL 68.732813 103.62606 \nL 68.846961 104.072758 \nL 68.86979 103.926 \nL 68.89262 103.779736 \nL 68.938279 104.073736 \nL 68.961108 103.927945 \nL 69.006768 104.22 \nL 69.052427 103.92987 \nL 69.189404 103.645406 \nL 69.235063 103.933634 \nL 69.303552 103.792532 \nL 69.486188 102.953968 \nL 69.509018 103.096436 \nL 69.851461 104.631507 \nL 69.91995 104.493066 \nL 69.942779 104.628963 \nL 70.148245 105.295609 \nL 70.308052 104.885158 \nL 70.513518 105.5325 \nL 70.764643 104.349136 \nL 70.787473 104.477894 \nL 70.878791 104.732791 \nL 70.901621 104.604033 \nL 71.107087 103.967279 \nL 71.175575 103.842538 \nL 71.266894 104.345104 \nL 71.381041 103.723096 \nL 71.4267 103.972242 \nL 71.44953 104.0963 \nL 71.495189 103.84993 \nL 71.563678 103.974313 \nL 71.609337 103.730004 \nL 71.632166 103.85301 \nL 71.677826 103.610036 \nL 71.700655 103.732706 \nL 71.723485 103.611729 \nL 71.769144 103.856038 \nL 71.791973 103.735387 \nL 71.860462 104.099338 \nL 71.906121 103.859014 \nL 71.95178 103.620004 \nL 71.997439 103.86098 \nL 72.157246 104.22 \nL 72.202905 103.983534 \nL 72.248564 104.22 \nL 72.294224 104.455199 \nL 72.339883 104.22 \nL 72.362712 104.102871 \nL 72.408371 104.336819 \nL 72.591008 104.797979 \nL 72.613837 104.681781 \nL 72.659496 104.91086 \nL 72.682326 104.794967 \nL 72.750815 104.907275 \nL 72.773644 104.791986 \nL 72.97911 104.22 \nL 73.093258 104.557071 \nL 73.116088 104.444427 \nL 73.161747 104.22 \nL 73.207406 104.443291 \nL 73.230235 104.554511 \nL 73.275894 104.331225 \nL 73.549849 103.453048 \nL 73.937952 105.078395 \nL 73.960781 104.970182 \nL 74.120588 104.64506 \nL 74.394543 105.477006 \nL 74.463031 105.368168 \nL 74.485861 105.471065 \nL 74.600009 105.981927 \nL 74.645668 105.770995 \nL 74.851134 105.2432 \nL 75.03377 105.639309 \nL 75.079429 105.433761 \nL 75.125088 105.632817 \nL 75.239236 105.725121 \nL 75.421873 105.313798 \nL 75.444702 105.411891 \nL 75.490361 105.211011 \nL 75.58168 105.009263 \nL 75.604509 105.106925 \nL 75.627339 105.204377 \nL 75.672998 105.005746 \nL 75.695827 105.102982 \nL 75.764316 105.197826 \nL 75.809975 105.000531 \nL 75.855634 105.19351 \nL 75.924123 105.093267 \nL 76.038271 104.991994 \nL 76.0611 105.087542 \nL 76.106759 104.893281 \nL 76.175248 104.603476 \nL 76.243737 104.697789 \nL 76.380714 104.884585 \nL 76.449203 104.977079 \nL 76.517691 104.691659 \nL 76.700328 105.061782 \nL 76.860135 104.591369 \nL 76.882964 104.683721 \nL 76.997112 104.958075 \nL 77.019942 104.865139 \nL 77.042771 104.772403 \nL 77.08843 104.954999 \nL 77.179748 105.13494 \nL 77.202578 105.042588 \nL 77.271067 105.131155 \nL 77.316726 104.947424 \nL 77.499362 105.302206 \nL 77.567851 105.208992 \nL 77.59068 105.297801 \nL 77.63634 105.474877 \nL 77.681999 105.293427 \nL 77.727658 105.112713 \nL 77.796146 105.199009 \nL 77.818976 105.286934 \nL 77.864635 105.107325 \nL 78.001612 104.749198 \nL 78.024442 104.836782 \nL 78.161419 105.358631 \nL 78.229908 105.267919 \nL 78.298397 105.177749 \nL 78.321226 105.263787 \nL 78.526692 105.858122 \nL 78.549522 105.770391 \nL 78.572351 105.682828 \nL 78.61801 105.851745 \nL 78.686499 105.93262 \nL 78.709329 105.84541 \nL 78.891965 105.49334 \nL 78.914795 105.576923 \nL 78.960454 105.405031 \nL 78.983283 105.488456 \nL 79.257238 104.805213 \nL 79.325727 104.886919 \nL 79.348556 104.803005 \nL 79.394215 104.635644 \nL 79.439874 104.800808 \nL 79.485534 104.965351 \nL 79.531193 104.798631 \nL 79.64534 104.713655 \nL 79.896466 105.278728 \nL 80.010613 105.192795 \nL 80.101932 105.350772 \nL 80.124761 105.269039 \nL 80.147591 105.187459 \nL 80.19325 105.346645 \nL 80.353057 105.73931 \nL 80.375886 105.658046 \nL 80.490034 105.572029 \nL 80.627011 105.722961 \nL 80.649841 105.642579 \nL 80.6955 105.797817 \nL 80.71833 105.717588 \nL 80.855307 105.866402 \nL 81.060773 105.464447 \nL 81.174921 105.536417 \nL 81.19775 105.457896 \nL 81.243409 105.61019 \nL 81.266239 105.531812 \nL 81.289069 105.607761 \nL 81.334728 105.451414 \nL 81.448875 105.369435 \nL 81.540194 105.51818 \nL 81.563023 105.440763 \nL 81.791319 104.976433 \nL 81.928296 105.424093 \nL 81.973955 105.271789 \nL 82.042444 105.344043 \nL 82.088103 105.192522 \nL 82.24791 105.558618 \nL 82.270739 105.483183 \nL 82.384887 105.255907 \nL 82.407717 105.32897 \nL 82.567524 105.689999 \nL 82.590353 105.615337 \nL 82.795819 105.240498 \nL 82.909967 105.454074 \nL 82.932797 105.380527 \nL 82.955626 105.307101 \nL 83.001285 105.450026 \nL 83.024115 105.521313 \nL 83.069774 105.374828 \nL 83.138263 105.156 \nL 83.183922 105.298237 \nL 83.366558 105.576923 \nL 83.480706 105.215806 \nL 83.549195 105.284358 \nL 83.617683 105.352586 \nL 83.640513 105.280947 \nL 83.663342 105.209423 \nL 83.709001 105.348958 \nL 83.731831 105.277556 \nL 83.868808 105.412843 \nL 83.891638 105.341782 \nL 83.937297 105.480003 \nL 83.960127 105.409058 \nL 84.028615 105.336457 \nL 84.074274 105.47403 \nL 84.188422 105.260912 \nL 84.211252 105.329433 \nL 84.439547 105.733575 \nL 84.462377 105.66365 \nL 84.508036 105.798679 \nL 84.622184 105.860929 \nL 84.781991 105.512061 \nL 84.80482 105.579015 \nL 84.918968 105.641491 \nL 85.010286 105.502172 \nL 85.033116 105.568622 \nL 85.192923 105.762663 \nL 85.215752 105.694467 \nL 85.261411 105.826069 \nL 85.466877 106.147506 \nL 85.558195 106.00918 \nL 85.581025 106.074053 \nL 85.740832 106.261969 \nL 85.923468 105.987931 \nL 85.969127 106.116073 \nL 86.014787 105.982695 \nL 86.174593 105.778765 \nL 86.197423 105.842518 \nL 86.243082 105.710522 \nL 86.311571 105.771905 \nL 86.380059 105.574936 \nL 86.402889 105.638421 \nL 86.448548 105.507592 \nL 86.471378 105.570982 \nL 86.654014 105.307311 \nL 86.836651 105.5554 \nL 86.973628 105.423015 \nL 87.064946 105.545843 \nL 87.087776 105.4818 \nL 87.179094 105.226562 \nL 87.247583 105.287187 \nL 87.430219 105.65567 \nL 87.453049 105.592279 \nL 87.498708 105.465761 \nL 87.544367 105.588405 \nL 87.704174 105.767368 \nL 87.88681 105.512534 \nL 88.000958 105.692044 \nL 88.023787 105.629731 \nL 88.092276 105.443303 \nL 88.137935 105.56377 \nL 88.320572 105.920829 \nL 88.343401 105.858952 \nL 88.434719 105.612314 \nL 88.480379 105.731309 \nL 88.503208 105.790683 \nL 88.548867 105.667882 \nL 88.571697 105.727177 \nL 88.731504 105.540002 \nL 88.799992 105.477432 \nL 88.91414 105.771558 \nL 88.93697 105.710875 \nL 88.982629 105.827967 \nL 89.165265 106.174732 \nL 89.188095 106.114228 \nL 89.256583 105.933193 \nL 89.302243 106.048898 \nL 89.576197 106.502546 \nL 89.781663 106.081739 \nL 89.804493 106.138658 \nL 89.827322 106.195493 \nL 89.872981 106.076844 \nL 89.895811 106.133611 \nL 90.055618 105.836231 \nL 90.078447 105.892855 \nL 90.261084 106.113686 \nL 90.420891 105.93373 \nL 90.603527 106.265875 \nL 90.626357 106.207768 \nL 90.900311 105.74166 \nL 91.060118 106.01542 \nL 91.082948 105.958207 \nL 91.105777 105.901067 \nL 91.151437 106.010862 \nL 91.174266 106.065657 \nL 91.219925 105.951604 \nL 91.242755 106.006331 \nL 91.356903 105.833755 \nL 91.379732 105.88835 \nL 91.562369 106.101306 \nL 91.767835 105.815633 \nL 91.859153 105.921433 \nL 91.881982 105.865524 \nL 92.01896 105.750114 \nL 92.041789 105.803779 \nL 92.087448 105.692727 \nL 92.110278 105.637306 \nL 92.155937 105.744447 \nL 92.315744 106.117356 \nL 92.384233 106.059754 \nL 92.407062 106.004548 \nL 92.452721 106.110385 \nL 92.49838 106.215964 \nL 92.566869 106.158461 \nL 92.726676 105.989361 \nL 92.749505 106.041869 \nL 92.795165 105.93262 \nL 92.817994 105.878093 \nL 92.863653 105.982931 \nL 92.932142 106.033058 \nL 92.954971 105.978673 \nL 92.977801 105.924346 \nL 93.02346 106.028684 \nL 93.04629 105.97443 \nL 93.206097 106.125883 \nL 93.251756 106.017844 \nL 93.297415 106.12132 \nL 93.388733 106.222152 \nL 93.411563 106.168298 \nL 93.617029 105.791261 \nL 93.639858 105.842671 \nL 93.662688 105.894023 \nL 93.708347 105.787534 \nL 93.731176 105.838828 \nL 93.754006 105.785678 \nL 93.799665 105.888087 \nL 93.936642 105.98608 \nL 94.164938 105.562624 \nL 94.187767 105.613444 \nL 94.438893 105.96349 \nL 94.461722 105.911224 \nL 94.507381 106.01164 \nL 94.667188 106.259309 \nL 94.690018 106.207174 \nL 94.712847 106.155102 \nL 94.758506 106.254604 \nL 94.826995 106.403417 \nL 94.872654 106.299473 \nL 94.941143 106.346519 \nL 95.055291 106.088 \nL 95.283586 106.378567 \nL 95.443393 106.12 \nL 95.466223 106.168897 \nL 95.740177 106.552809 \nL 95.763007 106.501889 \nL 95.808666 106.598425 \nL 95.945643 106.787971 \nL 95.968473 106.737182 \nL 96.173939 106.47902 \nL 96.356575 106.664565 \nL 96.470723 106.511541 \nL 96.493553 106.559007 \nL 96.6077 106.601159 \nL 96.699019 106.498945 \nL 96.721848 106.546154 \nL 96.744678 106.59331 \nL 96.790337 106.493945 \nL 96.881655 106.295862 \nL 96.927314 106.390038 \nL 96.950144 106.437047 \nL 96.995803 106.338339 \nL 97.064291 106.286814 \nL 97.087121 106.333724 \nL 97.201269 106.471713 \nL 97.224098 106.422606 \nL 97.361076 106.320003 \nL 97.475223 106.457129 \nL 97.498053 106.408349 \nL 97.543712 106.31095 \nL 97.612201 106.35502 \nL 97.65786 106.447514 \nL 97.703519 106.350436 \nL 98.045962 105.816806 \nL 98.114451 105.767368 \nL 98.16011 105.859404 \nL 98.342747 105.6659 \nL 98.411235 105.803316 \nL 98.479724 105.75432 \nL 98.571042 105.658298 \nL 98.593872 105.703914 \nL 98.730849 105.88415 \nL 98.753679 105.837077 \nL 98.776508 105.790052 \nL 98.822167 105.880669 \nL 98.959145 106.059417 \nL 98.981974 106.012497 \nL 99.118951 105.915272 \nL 99.233099 105.956582 \nL 99.370077 105.860083 \nL 99.575543 106.079231 \nL 99.598372 106.032947 \nL 99.644031 106.12164 \nL 99.666861 106.075415 \nL 99.73535 106.027375 \nL 99.826668 106.204051 \nL 99.849497 106.157967 \nL 99.895156 106.246035 \nL 99.917986 106.199998 \nL 99.986475 106.331768 \nL 100.032134 106.239847 \nL 100.100622 106.281583 \nL 100.169111 106.144199 \nL 100.21477 106.231656 \nL 100.283259 106.183969 \nL 100.374577 106.090907 \nL 100.397407 106.134489 \nL 100.465895 106.087138 \nL 100.511554 106.17408 \nL 100.625702 106.124874 \nL 100.73985 106.341042 \nL 100.808339 106.293738 \nL 100.990975 106.109686 \nL 101.196441 106.320003 \nL 101.333418 106.226531 \nL 101.401907 106.18 \nL 101.470396 106.307575 \nL 101.561714 106.216653 \nL 101.584544 106.259057 \nL 101.630203 106.343733 \nL 101.675862 106.255051 \nL 101.881328 106.030555 \nL 102.041135 106.153267 \nL 102.063964 106.109386 \nL 102.109623 106.193348 \nL 102.132453 106.149509 \nL 102.26943 106.229406 \nL 102.383578 106.011293 \nL 102.429237 106.094782 \nL 102.520555 106.17622 \nL 102.543385 106.13277 \nL 102.703192 105.999249 \nL 102.908658 106.202495 \nL 102.977146 106.073296 \nL 103.045635 106.112703 \nL 103.228272 106.273114 \nL 103.251101 106.230258 \nL 103.29676 106.312033 \nL 103.342419 106.39365 \nL 103.388078 106.308069 \nL 103.456567 106.263404 \nL 103.479397 106.304121 \nL 103.639204 106.421886 \nL 103.753351 106.292371 \nL 103.776181 106.332825 \nL 103.890329 106.369204 \nL 104.141454 106.070352 \nL 104.209942 106.026702 \nL 104.278431 106.147195 \nL 104.301261 106.105317 \nL 104.34692 106.185462 \nL 104.369749 106.143621 \nL 104.461068 106.221763 \nL 104.483897 106.18 \nL 104.552386 106.136502 \nL 104.575215 106.176378 \nL 104.620874 106.256013 \nL 104.689363 106.212531 \nL 104.82634 106.12593 \nL 104.940488 106.323851 \nL 104.986147 106.241082 \nL 105.077466 106.15669 \nL 105.100295 106.196134 \nL 105.305761 106.38885 \nL 105.328591 106.347718 \nL 105.37425 106.426002 \nL 105.465568 106.502067 \nL 105.488398 106.461014 \nL 105.671034 106.293417 \nL 105.693864 106.332336 \nL 105.739523 106.250792 \nL 105.85367 106.206485 \nL 106.036307 106.436874 \nL 106.059136 106.39631 \nL 106.104796 106.315292 \nL 106.150455 106.392414 \nL 106.173284 106.430923 \nL 106.218943 106.350052 \nL 106.241773 106.388529 \nL 106.515728 106.063218 \nL 106.584216 106.17826 \nL 106.629875 106.098262 \nL 106.789682 105.975419 \nL 106.835341 106.051815 \nL 106.881 105.972317 \nL 107.132126 105.692585 \nL 107.177785 105.768729 \nL 107.223444 105.689999 \nL 107.40608 105.453564 \nL 107.42891 105.491558 \nL 107.520228 105.566272 \nL 107.543058 105.527238 \nL 107.794183 105.253147 \nL 107.885501 105.404147 \nL 107.93116 105.326794 \nL 108.273603 104.902544 \nL 108.43341 105.013916 \nL 108.616047 104.785141 \nL 108.638876 104.822562 \nL 108.775854 105.046405 \nL 108.821513 104.970639 \nL 108.912831 104.819492 \nL 108.95849 104.893854 \nL 109.072638 105.0045 \nL 109.095467 104.966823 \nL 109.141126 104.891572 \nL 109.186786 104.965561 \nL 109.369422 105.111662 \nL 109.46074 105.110158 \nL 109.552058 105.108665 \nL 109.620547 105.070567 \nL 109.643377 105.107177 \nL 109.780354 105.178695 \nL 109.96299 105.028499 \nL 110.168456 105.208545 \nL 110.236945 105.170747 \nL 110.259775 105.206905 \nL 110.442411 105.349368 \nL 110.670707 105.127034 \nL 110.762025 105.125546 \nL 110.784854 105.088967 \nL 110.830514 105.160606 \nL 110.944661 105.194787 \nL 111.081639 105.120368 \nL 111.446912 105.615458 \nL 111.469741 105.579126 \nL 111.720866 105.323834 \nL 111.766525 105.394101 \nL 111.812184 105.322057 \nL 112.086139 105.03372 \nL 112.177457 105.032416 \nL 112.291605 104.925034 \nL 112.314435 104.959994 \nL 112.405753 105.029172 \nL 112.428582 104.993687 \nL 112.474242 104.922789 \nL 112.519901 104.992451 \nL 112.634048 105.02596 \nL 112.679708 104.955294 \nL 112.725367 105.024683 \nL 113.04498 105.368168 \nL 113.181958 105.296035 \nL 113.318935 105.362758 \nL 113.433083 105.256832 \nL 113.455912 105.290977 \nL 113.615719 105.460315 \nL 113.638549 105.425386 \nL 113.707038 105.38958 \nL 113.729867 105.423509 \nL 113.775526 105.49129 \nL 113.821185 105.421633 \nL 113.958163 105.35033 \nL 114.003822 105.417905 \nL 114.049481 105.34858 \nL 114.209288 105.2432 \nL 114.254947 105.310571 \nL 114.300606 105.241623 \nL 114.437583 105.103361 \nL 114.460413 105.13698 \nL 114.506072 105.204145 \nL 114.551731 105.135571 \nL 114.711538 105.031659 \nL 114.825686 105.063859 \nL 115.031152 104.892771 \nL 115.190959 104.991626 \nL 115.327936 104.92292 \nL 115.442084 104.954999 \nL 115.556232 104.920265 \nL 115.579061 104.953333 \nL 115.62472 104.886162 \nL 115.693209 104.852138 \nL 115.716038 104.885158 \nL 115.875845 104.98292 \nL 116.035652 104.881668 \nL 116.1498 104.913447 \nL 116.17263 104.88018 \nL 116.218289 104.945652 \nL 116.537902 105.270001 \nL 116.606391 105.236056 \nL 116.629221 105.26844 \nL 116.697709 105.299998 \nL 116.720539 105.266884 \nL 116.903175 105.068075 \nL 116.926005 105.100369 \nL 117.222789 105.388213 \nL 117.336937 105.288895 \nL 117.382596 105.352843 \nL 117.496744 105.383077 \nL 117.656551 105.218976 \nL 117.70221 105.28265 \nL 117.839187 105.344589 \nL 118.044653 105.244835 \nL 118.067483 105.276478 \nL 118.113142 105.211731 \nL 118.295778 105.145066 \nL 118.409926 105.175236 \nL 118.432756 105.143063 \nL 118.501244 105.237449 \nL 118.843688 105.579841 \nL 119.003494 105.418715 \nL 119.049154 105.480902 \nL 119.140472 105.542058 \nL 119.163301 105.510115 \nL 119.323108 105.475518 \nL 119.460086 105.598125 \nL 119.482915 105.566325 \nL 119.802529 105.310429 \nL 119.985165 105.431621 \nL 120.144972 105.397655 \nL 120.373268 105.578826 \nL 120.555904 105.513438 \nL 120.692882 105.633658 \nL 120.715711 105.602446 \nL 120.738541 105.571256 \nL 120.807029 105.661878 \nL 121.012495 105.810292 \nL 121.126643 105.838071 \nL 121.263621 105.834717 \nL 121.469087 105.738596 \nL 121.560405 105.736508 \nL 121.583234 105.705665 \nL 121.720212 105.64209 \nL 121.743041 105.671851 \nL 121.880019 105.66887 \nL 122.108314 105.543603 \nL 122.199632 105.601879 \nL 122.245291 105.540901 \nL 122.33661 105.539103 \nL 122.359439 105.568622 \nL 122.496417 105.565878 \nL 122.633394 105.443755 \nL 122.679053 105.502582 \nL 122.975837 105.70485 \nL 123.089985 105.672708 \nL 123.112815 105.701853 \nL 123.36394 105.903091 \nL 123.386769 105.87301 \nL 123.523747 105.810781 \nL 123.546576 105.839701 \nL 123.706383 105.865303 \nL 123.889019 105.802328 \nL 124.003167 105.887462 \nL 124.048826 105.827888 \nL 124.185804 105.707994 \nL 124.231463 105.765323 \nL 124.459758 105.876474 \nL 124.642395 105.756181 \nL 124.665224 105.784653 \nL 124.733713 105.812059 \nL 124.779372 105.753158 \nL 125.007668 105.632817 \nL 125.213134 105.772415 \nL 125.235963 105.743169 \nL 125.39577 105.711027 \nL 125.578407 105.764355 \nL 125.715384 105.704272 \nL 125.738213 105.732324 \nL 125.806702 105.81638 \nL 125.875191 105.729396 \nL 126.012168 105.726478 \nL 126.171975 105.751449 \nL 126.308952 105.691886 \nL 126.331782 105.719712 \nL 126.537248 105.800041 \nL 126.834032 105.596805 \nL 126.971009 105.594182 \nL 127.176475 105.506367 \nL 127.359112 105.670474 \nL 127.404771 105.613807 \nL 127.655896 105.470077 \nL 127.838533 105.577775 \nL 127.861362 105.549649 \nL 127.998339 105.436552 \nL 128.043999 105.491053 \nL 128.295124 105.624369 \nL 128.317953 105.596406 \nL 128.386442 105.677623 \nL 128.523419 105.729806 \nL 128.546249 105.70189 \nL 128.660397 105.562592 \nL 128.728885 105.643462 \nL 128.843033 105.613928 \nL 128.934351 105.557603 \nL 128.98001 105.611341 \nL 129.208306 105.770233 \nL 129.231135 105.742565 \nL 129.413772 105.684573 \nL 129.573579 105.708493 \nL 129.779045 105.623428 \nL 129.870363 105.729537 \nL 129.938852 105.647358 \nL 130.03017 105.645618 \nL 130.052999 105.672072 \nL 130.075829 105.698515 \nL 130.144318 105.616588 \nL 130.53242 105.315486 \nL 130.669397 105.366838 \nL 130.692227 105.339832 \nL 130.829204 105.284574 \nL 130.852034 105.31086 \nL 131.0575 105.387509 \nL 131.240136 105.278823 \nL 131.262966 105.304966 \nL 131.422773 105.329102 \nL 131.445602 105.302369 \nL 131.514091 105.380527 \nL 131.605409 105.379139 \nL 131.628239 105.352459 \nL 131.696727 105.325133 \nL 131.742387 105.377068 \nL 131.902193 105.400899 \nL 131.970682 105.373625 \nL 132.016341 105.425349 \nL 132.130489 105.397397 \nL 132.221807 105.291466 \nL 132.290296 105.368846 \nL 132.58708 105.546511 \nL 132.701228 105.57053 \nL 132.815376 105.594477 \nL 132.838205 105.568149 \nL 133.043671 105.487021 \nL 133.249137 105.561052 \nL 133.500262 105.42822 \nL 133.728558 105.527238 \nL 133.911194 105.473058 \nL 134.071001 105.496042 \nL 134.162319 105.494565 \nL 134.185149 105.519683 \nL 134.459104 105.667566 \nL 134.64174 105.512213 \nL 134.687399 105.562119 \nL 134.710229 105.587048 \nL 134.778717 105.509989 \nL 134.892865 105.432373 \nL 134.938524 105.482163 \nL 135.121161 105.580025 \nL 135.14399 105.554454 \nL 135.349456 105.475697 \nL 135.554922 105.547636 \nL 135.828877 105.393339 \nL 136.011513 105.4405 \nL 136.034343 105.415256 \nL 136.102832 105.488887 \nL 136.285468 105.535676 \nL 136.490934 105.45807 \nL 136.513764 105.482473 \nL 136.582252 105.407212 \nL 136.6964 105.380853 \nL 136.71923 105.40522 \nL 136.924696 105.525387 \nL 136.947525 105.5004 \nL 137.312798 105.200544 \nL 137.335628 105.224779 \nL 137.449775 105.247858 \nL 137.472605 105.223108 \nL 137.655241 105.172061 \nL 137.883537 105.26681 \nL 138.089003 105.191365 \nL 138.203151 105.214281 \nL 138.22598 105.189762 \nL 138.362958 105.188169 \nL 138.385787 105.212099 \nL 138.454276 105.138752 \nL 138.659742 105.064132 \nL 138.796719 105.11091 \nL 138.819549 105.086596 \nL 139.025015 105.012433 \nL 139.27614 105.177655 \nL 139.298969 105.153461 \nL 139.435947 105.104149 \nL 139.458776 105.127801 \nL 139.664242 105.197085 \nL 139.77839 105.21957 \nL 139.846879 105.242538 \nL 139.892538 105.194456 \nL 140.029515 105.192879 \nL 140.30347 105.378971 \nL 140.3263 105.355014 \nL 140.508936 105.305392 \nL 140.714402 105.373404 \nL 140.874209 105.300766 \nL 140.897038 105.323966 \nL 141.056845 105.345357 \nL 141.170993 105.320449 \nL 141.193823 105.343564 \nL 141.239482 105.389759 \nL 141.30797 105.318703 \nL 141.536266 105.175909 \nL 141.559096 105.198962 \nL 141.718902 105.266952 \nL 141.741732 105.243416 \nL 141.83305 105.19587 \nL 141.878709 105.241802 \nL 142.038516 105.263099 \nL 142.152664 105.192285 \nL 142.198323 105.238048 \nL 142.38096 105.282093 \nL 142.540766 105.211011 \nL 142.563596 105.233795 \nL 142.723403 105.25494 \nL 142.769062 105.20843 \nL 142.837551 105.276562 \nL 143.043017 105.342839 \nL 143.179994 105.341088 \nL 143.202824 105.363673 \nL 143.271312 105.294216 \nL 143.294142 105.271089 \nL 143.36263 105.33877 \nL 143.476778 105.314519 \nL 143.727903 105.197726 \nL 143.88771 105.21866 \nL 144.207324 105.034156 \nL 144.344301 105.032905 \nL 144.43562 105.077186 \nL 144.686745 105.187254 \nL 144.846552 105.163076 \nL 145.120506 105.294515 \nL 145.234654 105.315512 \nL 145.41729 105.357921 \nL 145.622756 105.288554 \nL 145.736904 105.26497 \nL 145.9652 105.173633 \nL 146.147836 105.215984 \nL 146.307643 105.192143 \nL 146.49028 105.2343 \nL 146.832723 105.0328 \nL 146.946871 105.009852 \nL 147.106678 104.986574 \nL 147.312144 105.050427 \nL 147.540439 104.961176 \nL 147.677416 104.960078 \nL 147.860053 104.915171 \nL 147.974201 104.892618 \nL 148.179667 104.826184 \nL 148.270985 104.782334 \nL 148.54494 104.651295 \nL 148.659087 104.629231 \nL 148.796065 104.628631 \nL 148.978701 104.670767 \nL 149.206997 104.584019 \nL 149.366804 104.60478 \nL 149.640758 104.475775 \nL 149.891883 104.581391 \nL 150.120179 104.495689 \nL 150.371304 104.600721 \nL 150.622429 104.494238 \nL 150.713747 104.451829 \nL 150.896384 104.409314 \nL 151.010532 104.388081 \nL 151.284486 104.261899 \nL 151.421464 104.261841 \nL 151.649759 104.178258 \nL 151.786736 104.178321 \nL 151.923714 104.178374 \nL 152.174839 104.282276 \nL 152.380305 104.22 \nL 152.517282 104.22 \nL 152.65426 104.22 \nL 152.745578 104.178732 \nL 153.042362 104.034833 \nL 153.224998 104.076249 \nL 153.361976 104.076449 \nL 153.544612 104.117654 \nL 153.65876 104.13822 \nL 154.001203 104.321873 \nL 154.115351 104.342102 \nL 154.229499 104.321636 \nL 154.343647 104.341823 \nL 154.571942 104.422573 \nL 154.937215 104.22 \nL 155.119852 104.260291 \nL 155.348147 104.179804 \nL 155.462295 104.159764 \nL 155.576443 104.179888 \nL 155.781909 104.240014 \nL 155.918886 104.239988 \nL 156.101522 104.279852 \nL 156.261329 104.259839 \nL 156.466795 104.319391 \nL 156.695091 104.239835 \nL 156.809239 104.22 \nL 156.969046 104.200223 \nL 157.151682 104.239746 \nL 157.357148 104.180593 \nL 157.539784 104.22 \nL 157.722421 104.180729 \nL 157.859398 104.180782 \nL 158.110523 104.083073 \nL 158.224671 104.063685 \nL 158.361648 104.063895 \nL 158.544285 104.103123 \nL 158.704092 104.083861 \nL 158.932387 104.161783 \nL 159.115024 104.123143 \nL 159.32049 104.181329 \nL 159.571615 104.084986 \nL 159.708592 104.085165 \nL 159.84557 104.085344 \nL 159.982547 104.085523 \nL 160.096695 104.104858 \nL 160.210843 104.085817 \nL 160.370649 104.06687 \nL 160.644604 104.181823 \nL 160.8729 104.105699 \nL 160.987047 104.086795 \nL 161.124025 104.086963 \nL 161.420809 104.22 \nL 161.603445 104.182159 \nL 161.808911 104.238884 \nL 161.90023 104.276598 \nL 162.060037 104.29535 \nL 162.288332 104.22 \nL 162.607946 104.369939 \nL 162.813412 104.31353 \nL 162.90473 104.276073 \nL 163.018878 104.294683 \nL 163.270003 104.387645 \nL 163.40698 104.387434 \nL 163.612446 104.442823 \nL 163.749424 104.44254 \nL 163.909231 104.460729 \nL 164.046208 104.46043 \nL 164.183185 104.460125 \nL 164.342992 104.44133 \nL 164.662606 104.587805 \nL 164.890901 104.513632 \nL 165.119197 104.58628 \nL 165.256174 104.585823 \nL 165.393152 104.585371 \nL 165.530129 104.584913 \nL 165.689936 104.602609 \nL 165.98672 104.474387 \nL 166.192186 104.528331 \nL 166.397652 104.473446 \nL 166.694436 104.59916 \nL 166.922732 104.526312 \nL 167.151027 104.597614 \nL 167.379323 104.525066 \nL 167.630448 104.613911 \nL 167.790255 104.595469 \nL 168.018551 104.666083 \nL 168.246846 104.593955 \nL 168.406653 104.611209 \nL 168.589289 104.575072 \nL 168.931733 104.733306 \nL 169.114369 104.697137 \nL 169.251347 104.696564 \nL 169.411153 104.678275 \nL 169.57096 104.695234 \nL 169.844915 104.588746 \nL 170.09604 104.675541 \nL 170.278677 104.674821 \nL 170.438483 104.691659 \nL 170.666779 104.655858 \nL 170.849415 104.655169 \nL 171.100541 104.60212 \nL 171.374495 104.670531 \nL 171.671279 104.582963 \nL 171.876745 104.599575 \nL 172.1507 104.529834 \nL 172.401825 104.580702 \nL 172.65295 104.528509 \nL 172.904075 104.579162 \nL 173.086712 104.578605 \nL 173.429155 104.696759 \nL 173.634621 104.678932 \nL 173.908576 104.745708 \nL 174.091212 104.744898 \nL 174.387997 104.828045 \nL 174.570633 104.827114 \nL 174.798929 104.859619 \nL 174.935906 104.892513 \nL 175.187031 104.941436 \nL 175.438156 104.889706 \nL 175.666452 104.921858 \nL 175.940406 104.853573 \nL 176.237191 104.93518 \nL 176.374168 104.967601 \nL 176.488316 104.917101 \nL 176.739441 104.86597 \nL 176.990566 104.91423 \nL 177.150373 104.929828 \nL 177.333009 104.928766 \nL 177.515646 104.927704 \nL 177.766771 104.975528 \nL 177.995066 104.941336 \nL 178.200532 104.956503 \nL 178.405998 104.938934 \nL 178.634294 104.970224 \nL 178.908249 104.903469 \nL 179.182203 104.966907 \nL 179.319181 104.998523 \nL 179.570306 105.045511 \nL 179.912749 104.930249 \nL 180.209533 105.009079 \nL 180.437829 104.975497 \nL 180.574806 104.942556 \nL 180.757443 104.941504 \nL 180.940079 104.940458 \nL 181.259693 104.842812 \nL 181.579307 104.936815 \nL 181.830432 104.887698 \nL 181.967409 104.855219 \nL 182.195705 104.822372 \nL 182.401171 104.837224 \nL 182.538148 104.868183 \nL 182.92625 105.008065 \nL 183.131716 104.991063 \nL 183.382842 105.036669 \nL 183.633967 104.988046 \nL 183.793774 104.971438 \nL 183.95358 104.986143 \nL 184.204706 105.031464 \nL 184.387342 105.030318 \nL 184.684126 105.1062 \nL 184.889592 105.089272 \nL 185.209206 105.180041 \nL 185.369013 105.19433 \nL 185.688627 105.284511 \nL 185.962581 105.2207 \nL 186.122388 105.204098 \nL 186.282195 105.218261 \nL 186.53332 105.262336 \nL 186.693127 105.276378 \nL 186.989911 105.350378 \nL 187.469332 105.14842 \nL 187.651968 105.147142 \nL 187.857434 105.13053 \nL 188.040071 105.129278 \nL 188.314026 105.066913 \nL 188.451003 105.035828 \nL 188.679298 105.004269 \nL 188.976083 105.077774 \nL 189.455503 104.879775 \nL 189.729458 104.938292 \nL 189.866435 104.967459 \nL 190.094731 104.996042 \nL 190.277367 104.99499 \nL 190.460004 104.993944 \nL 190.802447 104.888071 \nL 190.939424 104.857732 \nL 191.099231 104.871795 \nL 191.441675 104.973594 \nL 191.6928 104.927962 \nL 191.943925 104.970829 \nL 192.149391 104.954999 \nL 192.377686 104.98313 \nL 192.605982 104.95256 \nL 192.879937 105.009589 \nL 193.016914 105.03802 \nL 193.24521 105.065835 \nL 193.427846 105.064716 \nL 193.72463 105.135571 \nL 193.838778 105.17838 \nL 193.975755 105.14842 \nL 194.204051 105.117934 \nL 194.614983 105.259687 \nL 194.820449 105.243737 \nL 194.957426 105.213923 \nL 195.117233 105.227177 \nL 195.322699 105.240067 \nL 195.550995 105.209723 \nL 195.77929 105.236755 \nL 196.053245 105.177607 \nL 196.372859 105.261001 \nL 196.555495 105.259655 \nL 196.760961 105.272372 \nL 196.989257 105.24228 \nL 197.126234 105.212925 \nL 197.3317 105.197327 \nL 197.582825 105.238017 \nL 197.788291 105.222435 \nL 198.062246 105.276878 \nL 198.3362 105.218597 \nL 198.541666 105.231209 \nL 199.043917 105.031743 \nL 199.272212 105.058402 \nL 199.614656 104.958832 \nL 200.025588 105.095743 \nL 200.276713 105.052598 \nL 200.573497 105.120142 \nL 200.801793 105.091075 \nL 200.984429 105.089987 \nL 201.235554 105.047136 \nL 201.44102 105.059737 \nL 201.623657 105.058691 \nL 202.034589 105.193447 \nL 202.194395 105.206085 \nL 202.377032 105.204865 \nL 202.582498 105.18983 \nL 203.016259 105.336798 \nL 203.176066 105.3492 \nL 203.313044 105.320969 \nL 203.632657 105.237223 \nL 203.769635 105.209187 \nL 203.975101 105.194288 \nL 204.363203 105.31322 \nL 204.54584 105.311885 \nL 204.728476 105.310549 \nL 204.933942 105.295609 \nL 205.116579 105.2943 \nL 205.230726 105.333739 \nL 205.57317 105.424918 \nL 205.847124 105.369272 \nL 206.029761 105.367884 \nL 206.212397 105.366496 \nL 206.395034 105.365108 \nL 206.668988 105.309871 \nL 207.057091 105.426401 \nL 207.308216 105.384707 \nL 207.445193 105.357212 \nL 207.719148 105.302369 \nL 207.924614 105.314098 \nL 208.221398 105.246192 \nL 208.426864 105.257957 \nL 208.677989 105.216904 \nL 208.860626 105.215721 \nL 209.111751 105.174858 \nL 209.271558 105.1608 \nL 209.65966 105.041132 \nL 209.796637 105.014358 \nL 209.933615 105.039676 \nL 210.207569 105.090181 \nL 210.413035 105.07606 \nL 210.641331 105.100706 \nL 210.823967 105.09967 \nL 210.938115 105.060247 \nL 211.18924 105.020177 \nL 211.371877 105.019241 \nL 211.623002 104.979345 \nL 211.896957 105.029409 \nL 212.079593 105.028468 \nL 212.376377 105.090985 \nL 212.604673 105.064143 \nL 212.878627 105.113749 \nL 213.015605 105.138484 \nL 213.449366 105.275905 \nL 213.700491 105.261532 \nL 213.905957 105.272872 \nL 214.248401 105.207315 \nL 214.408208 105.168386 \nL 214.750651 105.103261 \nL 214.933287 105.077044 \nL 215.230072 105.037715 \nL 215.549685 105.086307 \nL 215.709492 105.12307 \nL 215.869299 105.084582 \nL 216.120424 105.070724 \nL 216.34872 105.069521 \nL 216.554186 105.080913 \nL 216.736822 105.055016 \nL 216.965118 105.053839 \nL 217.261902 105.089577 \nL 217.444539 105.113418 \nL 217.718493 105.136686 \nL 217.923959 105.147899 \nL 218.289232 105.21989 \nL 218.608846 105.168654 \nL 218.859971 105.1795 \nL 219.088267 105.178159 \nL 219.385051 105.213214 \nL 219.567687 105.236608 \nL 219.841642 105.259371 \nL 220.275404 105.146879 \nL 220.526529 105.157651 \nL 220.891802 105.082679 \nL 221.074438 105.057455 \nL 221.302734 105.056304 \nL 221.553859 105.067144 \nL 221.850643 105.029398 \nL 222.170257 105.076076 \nL 222.5127 105.014163 \nL 222.786655 105.03689 \nL 222.992121 105.047888 \nL 223.266075 105.070493 \nL 223.677007 104.972826 \nL 223.882473 104.959973 \nL 224.179258 104.922931 \nL 224.407553 104.921985 \nL 224.59019 104.944995 \nL 224.864144 104.967559 \nL 225.06961 104.978504 \nL 225.412054 105.036117 \nL 225.640349 105.035029 \nL 225.822986 105.010557 \nL 226.211088 104.926353 \nL 226.530702 104.972038 \nL 226.827486 104.935548 \nL 227.12427 104.969441 \nL 227.398225 104.944869 \nL 227.64935 104.955488 \nL 227.968964 104.907517 \nL 228.425555 105.021923 \nL 228.767998 104.962344 \nL 229.019123 104.972858 \nL 229.224589 104.983535 \nL 229.589862 105.051205 \nL 229.909476 105.003591 \nL 230.137772 105.002566 \nL 230.388897 104.989954 \nL 230.617192 104.988955 \nL 230.891147 104.964835 \nL 231.187931 104.997897 \nL 231.324908 105.043019 \nL 231.598863 105.064563 \nL 232.032625 104.96003 \nL 232.329409 104.992887 \nL 232.649023 104.946115 \nL 232.831659 104.922699 \nL 233.31108 104.796471 \nL 233.585034 104.818156 \nL 234.018796 104.715379 \nL 234.452558 104.815265 \nL 234.703683 104.803215 \nL 235.023296 104.84696 \nL 235.479888 104.7337 \nL 235.685354 104.721961 \nL 236.027797 104.665342 \nL 236.256092 104.664779 \nL 236.644195 104.586159 \nL 237.055127 104.673895 \nL 237.214934 104.706684 \nL 237.4204 104.695087 \nL 237.648695 104.694493 \nL 237.94548 104.726772 \nL 238.173775 104.726135 \nL 238.493389 104.769191 \nL 238.721684 104.768508 \nL 238.904321 104.746044 \nL 239.155446 104.734384 \nL 239.543549 104.809745 \nL 239.771844 104.809019 \nL 240.045799 104.829927 \nL 240.251265 104.840131 \nL 240.570879 104.882503 \nL 240.822004 104.870764 \nL 241.02747 104.859209 \nL 241.255765 104.858426 \nL 241.666697 104.943392 \nL 242.03197 104.877325 \nL 242.283095 104.887203 \nL 242.465732 104.908053 \nL 242.694027 104.907217 \nL 242.922323 104.906381 \nL 243.150618 104.905545 \nL 243.333255 104.926285 \nL 243.58438 104.936032 \nL 243.789846 104.945925 \nL 244.063801 104.966192 \nL 244.383414 104.922363 \nL 244.61171 104.921517 \nL 244.817176 104.931374 \nL 245.022642 104.920003 \nL 245.365085 104.865807 \nL 245.63904 104.886021 \nL 245.958654 104.842686 \nL 246.346756 104.91515 \nL 246.64354 104.882525 \nL 246.894665 104.892161 \nL 247.214279 104.8491 \nL 247.579552 104.910697 \nL 247.899166 104.867762 \nL 248.036143 104.825537 \nL 248.21878 104.84583 \nL 248.606882 104.917437 \nL 248.766689 104.948065 \nL 248.972155 104.936904 \nL 249.24611 104.91514 \nL 249.428746 104.893759 \nL 249.702701 104.872105 \nL 249.885337 104.850814 \nL 250.182121 104.818876 \nL 250.456076 104.838659 \nL 250.821349 104.775752 \nL 251.118133 104.805739 \nL 251.414917 104.77407 \nL 251.688872 104.793789 \nL 252.099804 104.710795 \nL 252.282441 104.689909 \nL 252.465077 104.709886 \nL 252.670543 104.699182 \nL 252.944498 104.678154 \nL 253.309771 104.738285 \nL 253.652214 104.686665 \nL 253.880509 104.686129 \nL 254.131635 104.695665 \nL 254.519737 104.765443 \nL 254.86218 104.734258 \nL 255.181794 104.753567 \nL 255.547067 104.712399 \nL 255.706874 104.661804 \nL 256.003658 104.651127 \nL 256.209124 104.620635 \nL 256.460249 104.63014 \nL 256.757033 104.639524 \nL 257.099477 104.608896 \nL 257.46475 104.648009 \nL 257.715875 104.657419 \nL 257.967 104.646953 \nL 258.332273 104.606536 \nL 258.697546 104.645417 \nL 258.9715 104.644844 \nL 259.154137 104.60498 \nL 259.565069 104.545096 \nL 259.907512 104.574057 \nL 260.067319 104.622917 \nL 260.295615 104.60284 \nL 260.683717 104.553129 \nL 260.957672 104.552682 \nL 261.231626 104.55224 \nL 261.57407 104.580955 \nL 261.802365 104.600048 \nL 262.258956 104.676997 \nL 262.829695 104.549685 \nL 262.989502 104.500983 \nL 263.423264 104.432714 \nL 263.697218 104.432435 \nL 264.222298 104.325952 \nL 264.541912 104.345025 \nL 264.884355 104.316016 \nL 265.340946 104.392455 \nL 265.820367 104.306028 \nL 266.071492 104.296381 \nL 266.345447 104.296281 \nL 266.665061 104.315207 \nL 266.916186 104.324606 \nL 267.19014 104.32447 \nL 267.395606 104.352832 \nL 267.646732 104.343196 \nL 268.012004 104.305144 \nL 268.400107 104.352206 \nL 268.76538 104.314271 \nL 269.176312 104.370543 \nL 269.495926 104.351528 \nL 269.76988 104.35136 \nL 270.089494 104.332429 \nL 270.31779 104.313593 \nL 270.637403 104.294762 \nL 270.957017 104.313314 \nL 271.208142 104.322525 \nL 271.482097 104.322398 \nL 271.84737 104.285052 \nL 272.144154 104.294241 \nL 272.440938 104.284873 \nL 272.646404 104.257036 \nL 272.988848 104.229242 \nL 273.308461 104.247695 \nL 273.513927 104.275331 \nL 273.856371 104.302868 \nL 274.039007 104.3396 \nL 274.244473 104.311916 \nL 274.586916 104.284237 \nL 274.792382 104.256674 \nL 275.089167 104.247469 \nL 275.385951 104.256574 \nL 275.774053 104.210874 \nL 275.95669 104.1744 \nL 276.43611 104.092599 \nL 276.755724 104.110957 \nL 277.212315 104.038629 \nL 277.5091 104.047934 \nL 277.805884 104.039113 \nL 278.125498 104.057439 \nL 278.353793 104.07565 \nL 278.650577 104.08485 \nL 278.993021 104.05807 \nL 279.289805 104.06727 \nL 279.586589 104.05849 \nL 279.906203 104.076649 \nL 280.180158 104.076817 \nL 280.385624 104.050132 \nL 280.659578 104.050331 \nL 280.933533 104.050542 \nL 281.230317 104.041857 \nL 281.481442 104.033151 \nL 281.801056 104.015645 \nL 282.257647 104.086995 \nL 282.485943 104.104848 \nL 282.874045 104.14926 \nL 283.239318 104.114058 \nL 283.467614 104.131796 \nL 283.467614 104.131796 \n\" clip-path=\"url(#p3da5497770)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#p3da5497770)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3da5497770\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnLhgNRM4XvK",
        "outputId": "378f6e3d-9a6d-4527-ba6d-af64ce4f2966"
      },
      "id": "CnLhgNRM4XvK",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        ...,\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cum_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWv_4Gk04gCy",
        "outputId": "2ed9dd54-3f88-4d3b-a932-40da88f1514e"
      },
      "id": "AWv_4Gk04gCy",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 0.0000e+00],\n",
              "        [2.0000e+00, 0.0000e+00],\n",
              "        [2.0000e+00, 1.0000e+00],\n",
              "        ...,\n",
              "        [4.9930e+03, 5.0050e+03],\n",
              "        [4.9940e+03, 5.0050e+03],\n",
              "        [4.9950e+03, 5.0050e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "estimates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaqUcGJm5AiR",
        "outputId": "55c09bc2-692e-4b46-8b7c-981e3aacc887"
      },
      "id": "HaqUcGJm5AiR",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.6666667 , 0.33333334],\n",
              "       ...,\n",
              "       [0.49939987, 0.5006001 ],\n",
              "       [0.49944994, 0.50055003],\n",
              "       [0.4995    , 0.5005    ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cum_counts.sum(dim=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqnlyKsM5S29",
        "outputId": "e4729952-d951-4865-c9d6-a1401070f4f0"
      },
      "id": "RqnlyKsM5S29",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00],\n",
              "        [2.0000e+00],\n",
              "        [3.0000e+00],\n",
              "        ...,\n",
              "        [9.9980e+03],\n",
              "        [9.9990e+03],\n",
              "        [1.0000e+04]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40585d",
      "metadata": {
        "origin_pos": 29,
        "id": "ec40585d"
      },
      "source": [
        "Each solid curve corresponds to one of the two values of the coin\n",
        "and gives our estimated probability that the coin turns up that value\n",
        "after each group of experiments.\n",
        "The dashed black line gives the true underlying probability.\n",
        "As we get more data by conducting more experiments,\n",
        "the curves converge towards the true probability.\n",
        "You might already begin to see the shape\n",
        "of some of the more advanced questions\n",
        "that preoccupy statisticians:\n",
        "How quickly does this convergence happen?\n",
        "If we had already tested many coins\n",
        "manufactured at the same plant,\n",
        "how might we incorporate this information?\n",
        "\n",
        "##  A More Formal Treatment\n",
        "\n",
        "We have already gotten pretty far: posing\n",
        "a probabilistic model,\n",
        "generating synthetic data,\n",
        "running a statistical estimator,\n",
        "empirically assessing convergence,\n",
        "and reporting error metrics (checking the deviation).\n",
        "However, to go much further,\n",
        "we will need to be more precise.\n",
        "\n",
        "\n",
        "When dealing with randomness,\n",
        "we denote the set of possible outcomes $\\mathcal{S}$\n",
        "and call it the *sample space* or *outcome space*.\n",
        "Here, each element is a distinct possible *outcome*.\n",
        "In the case of rolling a single coin,\n",
        "$\\mathcal{S} = \\{\\textrm{heads}, \\textrm{tails}\\}$.\n",
        "For a single die, $\\mathcal{S} = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "When flipping two coins, possible outcomes are\n",
        "$\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails}), (\\textrm{tails}, \\textrm{heads}),  (\\textrm{tails}, \\textrm{tails})\\}$.\n",
        "*Events* are subsets of the sample space.\n",
        "For instance, the event \"the first coin toss comes up heads\"\n",
        "corresponds to the set $\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails})\\}$.\n",
        "Whenever the outcome $z$ of a random experiment satisfies\n",
        "$z \\in \\mathcal{A}$, then event $\\mathcal{A}$ has occurred.\n",
        "For a single roll of a die, we could define the events\n",
        "\"seeing a $5$\" ($\\mathcal{A} = \\{5\\}$)\n",
        "and \"seeing an odd number\"  ($\\mathcal{B} = \\{1, 3, 5\\}$).\n",
        "In this case, if the die came up $5$,\n",
        "we would say that both $\\mathcal{A}$ and $\\mathcal{B}$ occurred.\n",
        "On the other hand, if $z = 3$,\n",
        "then $\\mathcal{A}$ did not occur\n",
        "but $\\mathcal{B}$ did.\n",
        "\n",
        "\n",
        "A *probability* function maps events\n",
        "onto real values ${P: \\mathcal{A} \\subseteq \\mathcal{S} \\rightarrow [0,1]}$.\n",
        "The probability, denoted $P(\\mathcal{A})$, of an event $\\mathcal{A}$\n",
        "in the given sample space $\\mathcal{S}$,\n",
        "has the following properties:\n",
        "\n",
        "* The probability of any event $\\mathcal{A}$ is a nonnegative real number, i.e., $P(\\mathcal{A}) \\geq 0$;\n",
        "* The probability of the entire sample space is $1$, i.e., $P(\\mathcal{S}) = 1$;\n",
        "* For any countable sequence of events $\\mathcal{A}_1, \\mathcal{A}_2, \\ldots$ that are *mutually exclusive* (i.e., $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., $P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$.\n",
        "\n",
        "These axioms of probability theory,\n",
        "proposed by :citet:`Kolmogorov.1933`,\n",
        "can be applied to rapidly derive a number of important consequences.\n",
        "For instance, it follows immediately\n",
        "that the probability of any event $\\mathcal{A}$\n",
        "*or* its complement $\\mathcal{A}'$ occurring is 1\n",
        "(because $\\mathcal{A} \\cup \\mathcal{A}' = \\mathcal{S}$).\n",
        "We can also prove that $P(\\emptyset) = 0$\n",
        "because $1 = P(\\mathcal{S} \\cup \\mathcal{S}') = P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset) = 1 + P(\\emptyset)$.\n",
        "Consequently, the probability of any event $\\mathcal{A}$\n",
        "*and* its complement $\\mathcal{A}'$ occurring simultaneously\n",
        "is $P(\\mathcal{A} \\cap \\mathcal{A}') = 0$.\n",
        "Informally, this tells us that impossible events\n",
        "have zero probability of occurring.\n",
        "\n",
        "\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "When we spoke about events like the roll of a die\n",
        "coming up odds or the first coin toss coming up heads,\n",
        "we were invoking the idea of a *random variable*.\n",
        "Formally, random variables are mappings\n",
        "from an underlying sample space\n",
        "to a set of (possibly many) values.\n",
        "You might wonder how a random variable\n",
        "is different from the sample space,\n",
        "since both are collections of outcomes.\n",
        "Importantly, random variables can be much coarser\n",
        "than the raw sample space.\n",
        "We can define a binary random variable like \"greater than 0.5\"\n",
        "even when the underlying sample space is infinite,\n",
        "e.g., points on the line segment between $0$ and $1$.\n",
        "Additionally, multiple random variables\n",
        "can share the same underlying sample space.\n",
        "For example \"whether my home alarm goes off\"\n",
        "and \"whether my house was burgled\"\n",
        "are both binary random variables\n",
        "that share an underlying sample space.\n",
        "Consequently, knowing the value taken by one random variable\n",
        "can tell us something about the likely value of another random variable.\n",
        "Knowing that the alarm went off,\n",
        "we might suspect that the house was likely burgled.\n",
        "\n",
        "\n",
        "Every value taken by a random variable corresponds\n",
        "to a subset of the underlying sample space.\n",
        "Thus the occurrence where the random variable $X$\n",
        "takes value $v$, denoted by $X=v$, is an *event*\n",
        "and $P(X=v)$ denotes its probability.\n",
        "Sometimes this notation can get clunky,\n",
        "and we can abuse notation when the context is clear.\n",
        "For example, we might use $P(X)$ to refer broadly\n",
        "to the *distribution* of $X$, i.e.,\n",
        "the function that tells us the probability\n",
        "that $X$ takes any given value.\n",
        "Other times we write expressions\n",
        "like $P(X,Y) = P(X) P(Y)$,\n",
        "as a shorthand to express a statement\n",
        "that is true for all of the values\n",
        "that the random variables $X$ and $Y$ can take, i.e.,\n",
        "for all $i,j$ it holds that $P(X=i \\textrm{ and } Y=j) = P(X=i)P(Y=j)$.\n",
        "Other times, we abuse notation by writing\n",
        "$P(v)$ when the random variable is clear from the context.\n",
        "Since an event in probability theory is a set of outcomes from the sample space,\n",
        "we can specify a range of values for a random variable to take.\n",
        "For example, $P(1 \\leq X \\leq 3)$ denotes the probability of the event $\\{1 \\leq X \\leq 3\\}$.\n",
        "\n",
        "\n",
        "Note that there is a subtle difference\n",
        "between *discrete* random variables,\n",
        "like flips of a coin or tosses of a die,\n",
        "and *continuous* ones,\n",
        "like the weight and the height of a person\n",
        "sampled at random from the population.\n",
        "In this case we seldom really care about\n",
        "someone's exact height.\n",
        "Moreover, if we took precise enough measurements,\n",
        "we would find that no two people on the planet\n",
        "have the exact same height.\n",
        "In fact, with fine enough measurements,\n",
        "you would never have the same height\n",
        "when you wake up and when you go to sleep.\n",
        "There is little point in asking about\n",
        "the exact probability that someone\n",
        "is 1.801392782910287192 meters tall.\n",
        "Instead, we typically care more about being able to say\n",
        "whether someone's height falls into a given interval,\n",
        "say between 1.79 and 1.81 meters.\n",
        "In these cases we work with probability *densities*.\n",
        "The height of exactly 1.80 meters\n",
        "has no probability, but nonzero density.\n",
        "To work out the probability assigned to an interval,\n",
        "we must take an *integral* of the density\n",
        "over that interval.\n",
        "\n",
        "## Multiple Random Variables\n",
        "\n",
        "You might have noticed that we could not even\n",
        "make it through the previous section without\n",
        "making statements involving interactions\n",
        "among multiple random variables\n",
        "(recall $P(X,Y) = P(X) P(Y)$).\n",
        "Most of machine learning\n",
        "is concerned with such relationships.\n",
        "Here, the sample space would be\n",
        "the population of interest,\n",
        "say customers who transact with a business,\n",
        "photographs on the Internet,\n",
        "or proteins known to biologists.\n",
        "Each random variable would represent\n",
        "the (unknown) value of a different attribute.\n",
        "Whenever we sample an individual from the population,\n",
        "we observe a realization of each of the random variables.\n",
        "Because the values taken by random variables\n",
        "correspond to subsets of the sample space\n",
        "that could be overlapping, partially overlapping,\n",
        "or entirely disjoint,\n",
        "knowing the value taken by one random variable\n",
        "can cause us to update our beliefs\n",
        "about which values of another random variable are likely.\n",
        "If a patient walks into a hospital\n",
        "and we observe that they\n",
        "are having trouble breathing\n",
        "and have lost their sense of smell,\n",
        "then we believe that they are more likely\n",
        "to have COVID-19 than we might\n",
        "if they had no trouble breathing\n",
        "and a perfectly ordinary sense of smell.\n",
        "\n",
        "\n",
        "When working with multiple random variables,\n",
        "we can construct events corresponding\n",
        "to every combination of values\n",
        "that the variables can jointly take.\n",
        "The probability function that assigns\n",
        "probabilities to each of these combinations\n",
        "(e.g. $A=a$ and $B=b$)\n",
        "is called the *joint probability* function\n",
        "and simply returns the probability assigned\n",
        "to the intersection of the corresponding subsets\n",
        "of the sample space.\n",
        "The *joint probability* assigned to the event\n",
        "where random variables $A$ and $B$\n",
        "take values $a$ and $b$, respectively,\n",
        "is denoted $P(A = a, B = b)$,\n",
        "where the comma indicates \"and\".\n",
        "Note that for any values $a$ and $b$,\n",
        "it follows that\n",
        "\n",
        "$$P(A=a, B=b) \\leq P(A=a) \\textrm{ and } P(A=a, B=b) \\leq P(B = b),$$\n",
        "\n",
        "since for $A=a$ and $B=b$ to happen,\n",
        "$A=a$ has to happen *and* $B=b$ also has to happen.\n",
        "Interestingly, the joint probability\n",
        "tells us all that we can know about these\n",
        "random variables in a probabilistic sense,\n",
        "and can be used to derive many other\n",
        "useful quantities, including recovering the\n",
        "individual distributions $P(A)$ and $P(B)$.\n",
        "To recover $P(A=a)$ we simply sum up\n",
        "$P(A=a, B=v)$ over all values $v$\n",
        "that the random variable $B$ can take:\n",
        "$P(A=a) = \\sum_v P(A=a, B=v)$.\n",
        "\n",
        "\n",
        "The ratio $\\frac{P(A=a, B=b)}{P(A=a)} \\leq 1$\n",
        "turns out to be extremely important.\n",
        "It is called the *conditional probability*,\n",
        "and is denoted via the \"$\\mid$\" symbol:\n",
        "\n",
        "$$P(B=b \\mid A=a) = P(A=a,B=b)/P(A=a).$$\n",
        "\n",
        "It tells us the new probability\n",
        "associated with the event $B=b$,\n",
        "once we condition on the fact $A=a$ took place.\n",
        "We can think of this conditional probability\n",
        "as restricting attention only to the subset\n",
        "of the sample space associated with $A=a$\n",
        "and then renormalizing so that\n",
        "all probabilities sum to 1.\n",
        "Conditional probabilities\n",
        "are in fact just ordinary probabilities\n",
        "and thus respect all of the axioms,\n",
        "as long as we condition all terms\n",
        "on the same event and thus\n",
        "restrict attention to the same sample space.\n",
        "For instance, for disjoint events\n",
        "$\\mathcal{B}$ and $\\mathcal{B}'$, we have that\n",
        "$P(\\mathcal{B} \\cup \\mathcal{B}' \\mid A = a) = P(\\mathcal{B} \\mid A = a) + P(\\mathcal{B}' \\mid A = a)$.\n",
        "\n",
        "\n",
        "Using the definition of conditional probabilities,\n",
        "we can derive the famous result called *Bayes' theorem*.\n",
        "By construction, we have that $P(A, B) = P(B\\mid A) P(A)$\n",
        "and $P(A, B) = P(A\\mid B) P(B)$.\n",
        "Combining both equations yields\n",
        "$P(B\\mid A) P(A) = P(A\\mid B) P(B)$ and hence\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}.$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This simple equation has profound implications because\n",
        "it allows us to reverse the order of conditioning.\n",
        "If we know how to estimate $P(B\\mid A)$, $P(A)$, and $P(B)$,\n",
        "then we can estimate $P(A\\mid B)$.\n",
        "We often find it easier to estimate one term directly\n",
        "but not the other and Bayes' theorem can come to the rescue here.\n",
        "For instance, if we know the prevalence of symptoms for a given disease,\n",
        "and the overall prevalences of the disease and symptoms, respectively,\n",
        "we can determine how likely someone is\n",
        "to have the disease based on their symptoms.\n",
        "In some cases we might not have direct access to $P(B)$,\n",
        "such as the prevalence of symptoms.\n",
        "In this case a simplified version of Bayes' theorem comes in handy:\n",
        "\n",
        "$$P(A \\mid B) \\propto P(B \\mid A) P(A).$$\n",
        "\n",
        "Since we know that $P(A \\mid B)$ must be normalized to $1$, i.e., $\\sum_a P(A=a \\mid B) = 1$,\n",
        "we can use it to compute\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_a P(B \\mid A=a) P(A = a)}.$$\n",
        "\n",
        "In Bayesian statistics, we think of an observer\n",
        "as possessing some (subjective) prior beliefs\n",
        "about the plausibility of the available hypotheses\n",
        "encoded in the *prior* $P(H)$,\n",
        "and a *likelihood function* that says how likely\n",
        "one is to observe any value of the collected evidence\n",
        "for each of the hypotheses in the class $P(E \\mid H)$.\n",
        "Bayes' theorem is then interpreted as telling us\n",
        "how to update the initial *prior* $P(H)$\n",
        "in light of the available evidence $E$\n",
        "to produce *posterior* beliefs\n",
        "$P(H \\mid E) = \\frac{P(E \\mid H) P(H)}{P(E)}$.\n",
        "Informally, this can be stated as\n",
        "\"posterior equals prior times likelihood, divided by the evidence\".\n",
        "Now, because the evidence $P(E)$ is the same for all hypotheses,\n",
        "we can get away with simply normalizing over the hypotheses.\n",
        "\n",
        "Note that $\\sum_a P(A=a \\mid B) = 1$ also allows us to *marginalize* over random variables. That is, we can drop variables from a joint distribution such as $P(A, B)$. After all, we have that\n",
        "\n",
        "$$\\sum_a P(B \\mid A=a) P(A=a) = \\sum_a P(B, A=a) = P(B).$$\n",
        "\n",
        "Independence is another fundamentally important concept\n",
        "that forms the backbone of\n",
        "many important ideas in statistics.\n",
        "In short, two variables are *independent*\n",
        "if conditioning on the value of $A$ does not\n",
        "cause any change to the probability distribution\n",
        "associated with $B$ and vice versa.\n",
        "More formally, independence, denoted $A \\perp B$,\n",
        "requires that $P(A \\mid B) = P(A)$ and, consequently,\n",
        "that $P(A,B) = P(A \\mid B) P(B) = P(A) P(B)$.\n",
        "Independence is often an appropriate assumption.\n",
        "For example, if the random variable $A$\n",
        "represents the outcome from tossing one fair coin\n",
        "and the random variable $B$\n",
        "represents the outcome from tossing another,\n",
        "then knowing whether $A$ came up heads\n",
        "should not influence the probability\n",
        "of $B$ coming up heads.\n",
        "\n",
        "\n",
        "Independence is especially useful when it holds among the successive\n",
        "draws of our data from some underlying distribution\n",
        "(allowing us to make strong statistical conclusions)\n",
        "or when it holds among various variables in our data,\n",
        "allowing us to work with simpler models\n",
        "that encode this independence structure.\n",
        "On the other hand, estimating the dependencies\n",
        "among random variables is often the very aim of learning.\n",
        "We care to estimate the probability of disease given symptoms\n",
        "specifically because we believe\n",
        "that diseases and symptoms are *not* independent.\n",
        "\n",
        "\n",
        "Note that because conditional probabilities are proper probabilities,\n",
        "the concepts of independence and dependence also apply to them.\n",
        "Two random variables $A$ and $B$ are *conditionally independent*\n",
        "given a third variable $C$ if and only if $P(A, B \\mid C) = P(A \\mid C)P(B \\mid C)$.\n",
        "Interestingly, two variables can be independent in general\n",
        "but become dependent when conditioning on a third.\n",
        "This often occurs when the two random variables $A$ and $B$\n",
        "correspond to causes of some third variable $C$.\n",
        "For example, broken bones and lung cancer might be independent\n",
        "in the general population but if we condition on being in the hospital\n",
        "then we might find that broken bones are negatively correlated with lung cancer.\n",
        "That is because the broken bone *explains away* why some person is in the hospital\n",
        "and thus lowers the probability that they are hospitalized because of having lung cancer.\n",
        "\n",
        "\n",
        "And conversely, two dependent random variables\n",
        "can become independent upon conditioning on a third.\n",
        "This often happens when two otherwise unrelated events\n",
        "have a common cause.\n",
        "Shoe size and reading level are highly correlated\n",
        "among elementary school students,\n",
        "but this correlation disappears if we condition on age.\n",
        "\n",
        "\n",
        "\n",
        "## An Example\n",
        ":label:`subsec_probability_hiv_app`\n",
        "\n",
        "Let's put our skills to the test.\n",
        "Assume that a doctor administers an HIV test to a patient.\n",
        "This test is fairly accurate and fails only with 1% probability\n",
        "if the patient is healthy but reported as diseased,\n",
        "i.e., healthy patients test positive in 1% of cases.\n",
        "Moreover, it never fails to detect HIV if the patient actually has it.\n",
        "We use $D_1 \\in \\{0, 1\\}$ to indicate the diagnosis\n",
        "($0$ if negative and $1$ if positive)\n",
        "and $H \\in \\{0, 1\\}$ to denote the HIV status.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_1 = 1 \\mid H)$        |     1 |  0.01 |\n",
        "| $P(D_1 = 0 \\mid H)$        |     0 |  0.99 |\n",
        "\n",
        "Note that the column sums are all 1 (but the row sums do not),\n",
        "since they are conditional probabilities.\n",
        "Let's compute the probability of the patient having HIV\n",
        "if the test comes back positive, i.e., $P(H = 1 \\mid D_1 = 1)$.\n",
        "Intuitively this is going to depend on how common the disease is,\n",
        "since it affects the number of false alarms.\n",
        "Assume that the population is fairly free of the disease, e.g., $P(H=1) = 0.0015$.\n",
        "To apply Bayes' theorem, we need to apply marginalization\n",
        "to determine\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1)\n",
        "=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\\\\n",
        "=& P(D_1=1 \\mid H=0) P(H=0) + P(D_1=1 \\mid H=1) P(H=1) \\\\\n",
        "=& 0.011485.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This leads us to\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1=1 \\mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$\n",
        "\n",
        "In other words, there is only a 13.06% chance\n",
        "that the patient actually has HIV,\n",
        "despite the test being pretty accurate.\n",
        "As we can see, probability can be counterintuitive.\n",
        "What should a patient do upon receiving such terrifying news?\n",
        "Likely, the patient would ask the physician\n",
        "to administer another test to get clarity.\n",
        "The second test has different characteristics\n",
        "and it is not as good as the first one.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_2 = 1 \\mid H)$          |  0.98 |  0.03 |\n",
        "| $P(D_2 = 0 \\mid H)$          |  0.02 |  0.97 |\n",
        "\n",
        "Unfortunately, the second test comes back positive, too.\n",
        "Let's calculate the requisite probabilities to invoke Bayes' theorem\n",
        "by assuming conditional independence:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 0)\n",
        "& = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)\n",
        "=& 0.0003, \\\\\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 1)\n",
        "& = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)\n",
        "=& 0.98.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we can apply marginalization to obtain the probability\n",
        "that both tests come back positive:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "&P(D_1 = 1, D_2 = 1)\\\\\n",
        "&= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\\\\n",
        "&= P(D_1 = 1, D_2 = 1 \\mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \\mid H = 1)P(H=1)\\\\\n",
        "&= 0.00176955.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Finally, the probability of the patient having HIV given that both tests are positive is\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1, D_2 = 1)\n",
        "= \\frac{P(D_1 = 1, D_2 = 1 \\mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}\n",
        "= 0.8307.$$\n",
        "\n",
        "That is, the second test allowed us to gain much higher confidence that not all is well.\n",
        "Despite the second test being considerably less accurate than the first one,\n",
        "it still significantly improved our estimate.\n",
        "The assumption of both tests being conditionally independent of each other\n",
        "was crucial for our ability to generate a more accurate estimate.\n",
        "Take the extreme case where we run the same test twice.\n",
        "In this situation we would expect the same outcome both times,\n",
        "hence no additional insight is gained from running the same test again.\n",
        "The astute reader might have noticed that the diagnosis behaved\n",
        "like a classifier hiding in plain sight\n",
        "where our ability to decide whether a patient is healthy\n",
        "increases as we obtain more features (test outcomes).\n",
        "\n",
        "\n",
        "## Expectations\n",
        "\n",
        "Often, making decisions requires not just looking\n",
        "at the probabilities assigned to individual events\n",
        "but composing them together into useful aggregates\n",
        "that can provide us with guidance.\n",
        "For example, when random variables take continuous scalar values,\n",
        "we often care about knowing what value to expect *on average*.\n",
        "This quantity is formally called an *expectation*.\n",
        "If we are making investments,\n",
        "the first quantity of interest\n",
        "might be the return we can expect,\n",
        "averaging over all the possible outcomes\n",
        "(and weighting by the appropriate probabilities).\n",
        "For instance, say that with 50% probability,\n",
        "an investment might fail altogether,\n",
        "with 40% probability it might provide a 2$\\times$ return,\n",
        "and with 10% probability it might provide a 10$\\times$ return 10$\\times$.\n",
        "To calculate the expected return,\n",
        "we sum over all returns, multiplying each\n",
        "by the probability that they will occur.\n",
        "This yields the expectation\n",
        "$0.5 \\cdot 0 + 0.4 \\cdot 2 + 0.1 \\cdot 10 = 1.8$.\n",
        "Hence the expected return is 1.8$\\times$.\n",
        "\n",
        "\n",
        "In general, the *expectation* (or average)\n",
        "of the random variable $X$ is defined as\n",
        "\n",
        "$$E[X] = E_{x \\sim P}[x] = \\sum_{x} x P(X = x).$$\n",
        "\n",
        "Likewise, for densities we obtain $E[X] = \\int x \\;dp(x)$.\n",
        "Sometimes we are interested in the expected value\n",
        "of some function of $x$.\n",
        "We can calculate these expectations as\n",
        "\n",
        "$$E_{x \\sim P}[f(x)] = \\sum_x f(x) P(x) \\textrm{ and } E_{x \\sim P}[f(x)] = \\int f(x) p(x) \\;dx$$\n",
        "\n",
        "for discrete probabilities and densities, respectively.\n",
        "Returning to the investment example from above,\n",
        "$f$ might be the *utility* (happiness)\n",
        "associated with the return.\n",
        "Behavior economists have long noted\n",
        "that people associate greater disutility\n",
        "with losing money than the utility gained\n",
        "from earning one dollar relative to their baseline.\n",
        "Moreover, the value of money tends to be sub-linear.\n",
        "Possessing 100k dollars versus zero dollars\n",
        "can make the difference between paying the rent,\n",
        "eating well, and enjoying quality healthcare\n",
        "versus suffering through homelessness.\n",
        "On the other hand, the gains due to possessing\n",
        "200k versus 100k are less dramatic.\n",
        "Reasoning like this motivates the cliché\n",
        "that \"the utility of money is logarithmic\".\n",
        "\n",
        "\n",
        "If  the utility associated with a total loss were $-1$,\n",
        "and the utilities associated with returns of $1$, $2$, and $10$\n",
        "were $1$, $2$ and $4$, respectively,\n",
        "then the expected happiness of investing\n",
        "would be $0.5 \\cdot (-1) + 0.4 \\cdot 2 + 0.1 \\cdot 4 = 0.7$\n",
        "(an expected loss of utility of 30%).\n",
        "If indeed this were your utility function,\n",
        "you might be best off keeping the money in the bank.\n",
        "\n",
        "For financial decisions,\n",
        "we might also want to measure\n",
        "how *risky* an investment is.\n",
        "Here, we care not just about the expected value\n",
        "but how much the actual values tend to *vary*\n",
        "relative to this value.\n",
        "Note that we cannot just take\n",
        "the expectation of the difference\n",
        "between the actual and expected values.\n",
        "This is because the expectation of a difference\n",
        "is the difference of the expectations,\n",
        "i.e., $E[X - E[X]] = E[X] - E[E[X]] = 0$.\n",
        "However, we can look at the expectation\n",
        "of any non-negative function of this difference.\n",
        "The *variance* of a random variable is calculated by looking\n",
        "at the expected value of the *squared* differences:\n",
        "\n",
        "$$\\textrm{Var}[X] = E\\left[(X - E[X])^2\\right] = E[X^2] - E[X]^2.$$\n",
        "\n",
        "Here the equality follows by expanding\n",
        "$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$\n",
        "and taking expectations for each term.\n",
        "The square root of the variance is another\n",
        "useful quantity called the *standard deviation*.\n",
        "While this and the variance\n",
        "convey the same information (either can be calculated from the other),\n",
        "the standard deviation has the nice property\n",
        "that it is expressed in the same units\n",
        "as the original quantity represented\n",
        "by the random variable.\n",
        "\n",
        "Lastly, the variance of a function\n",
        "of a random variable\n",
        "is defined analogously as\n",
        "\n",
        "$$\\textrm{Var}_{x \\sim P}[f(x)] = E_{x \\sim P}[f^2(x)] - E_{x \\sim P}[f(x)]^2.$$\n",
        "\n",
        "Returning to our investment example,\n",
        "we can now compute the variance of the investment.\n",
        "It is given by $0.5 \\cdot 0 + 0.4 \\cdot 2^2 + 0.1 \\cdot 10^2 - 1.8^2 = 8.36$.\n",
        "For all intents and purposes this is a risky investment.\n",
        "Note that by mathematical convention mean and variance\n",
        "are often referenced as $\\mu$ and $\\sigma^2$.\n",
        "This is particularly the case whenever we use it\n",
        "to parametrize a Gaussian distribution.\n",
        "\n",
        "In the same way as we introduced expectations\n",
        "and variance for *scalar* random variables,\n",
        "we can do so for vector-valued ones.\n",
        "Expectations are easy, since we can apply them elementwise.\n",
        "For instance, $\\boldsymbol{\\mu} \\stackrel{\\textrm{def}}{=} E_{\\mathbf{x} \\sim P}[\\mathbf{x}]$\n",
        "has coordinates $\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$.\n",
        "*Covariances* are more complicated.\n",
        "We define them by taking expectations of the *outer product*\n",
        "of the difference between random variables and their mean:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} \\stackrel{\\textrm{def}}{=} \\textrm{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right].$$\n",
        "\n",
        "This matrix $\\boldsymbol{\\Sigma}$ is referred to as the covariance matrix.\n",
        "An easy way to see its effect is to consider some vector $\\mathbf{v}$\n",
        "of the same size as $\\mathbf{x}$.\n",
        "It follows that\n",
        "\n",
        "$$\\mathbf{v}^\\top \\boldsymbol{\\Sigma} \\mathbf{v} = E_{\\mathbf{x} \\sim P}\\left[\\mathbf{v}^\\top(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{v}\\right] = \\textrm{Var}_{x \\sim P}[\\mathbf{v}^\\top \\mathbf{x}].$$\n",
        "\n",
        "As such, $\\boldsymbol{\\Sigma}$ allows us to compute the variance\n",
        "for any linear function of $\\mathbf{x}$\n",
        "by a simple matrix multiplication.\n",
        "The off-diagonal elements tell us how correlated the coordinates are:\n",
        "a value of 0 means no correlation,\n",
        "where a larger positive value\n",
        "means that they are more strongly correlated.\n",
        "\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "In machine learning, there are many things to be uncertain about!\n",
        "We can be uncertain about the value of a label given an input.\n",
        "We can be uncertain about the estimated value of a parameter.\n",
        "We can even be uncertain about whether data arriving at deployment\n",
        "is even from the same distribution as the training data.\n",
        "\n",
        "By *aleatoric uncertainty*, we mean uncertainty\n",
        "that is intrinsic to the problem,\n",
        "and due to genuine randomness\n",
        "unaccounted for by the observed variables.\n",
        "By *epistemic uncertainty*, we mean uncertainty\n",
        "over a model's parameters, the sort of uncertainty\n",
        "that we can hope to reduce by collecting more data.\n",
        "We might have epistemic uncertainty\n",
        "concerning the probability\n",
        "that a coin turns up heads,\n",
        "but even once we know this probability,\n",
        "we are left with aleatoric uncertainty\n",
        "about the outcome of any future toss.\n",
        "No matter how long we watch someone tossing a fair coin,\n",
        "we will never be more or less than 50% certain\n",
        "that the next toss will come up heads.\n",
        "These terms come from mechanical modeling,\n",
        "(see e.g., :citet:`Der-Kiureghian.Ditlevsen.2009` for a review on this aspect of [uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)).\n",
        "It is worth noting, however, that these terms constitute a slight abuse of language.\n",
        "The term *epistemic* refers to anything concerning *knowledge*\n",
        "and thus, in the philosophical sense, all uncertainty is epistemic.\n",
        "\n",
        "\n",
        "We saw that sampling data from some unknown probability distribution\n",
        "can provide us with information that can be used to estimate\n",
        "the parameters of the data generating distribution.\n",
        "That said, the rate at which this is possible can be quite slow.\n",
        "In our coin tossing example (and many others)\n",
        "we can do no better than to design estimators\n",
        "that converge at a rate of $1/\\sqrt{n}$,\n",
        "where $n$ is the sample size (e.g., the number of tosses).\n",
        "This means that by going from 10 to 1000 observations (usually a very achievable task)\n",
        "we see a tenfold reduction of uncertainty,\n",
        "whereas the next 1000 observations help comparatively little,\n",
        "offering only a 1.41 times reduction.\n",
        "This is a persistent feature of machine learning:\n",
        "while there are often easy gains, it takes a very large amount of data,\n",
        "and often with it an enormous amount of computation, to make further gains.\n",
        "For an empirical review of this fact for large scale language models see :citet:`Revels.Lubin.Papamarkou.2016`.\n",
        "\n",
        "We also sharpened our language and tools for statistical modeling.\n",
        "In the process of that we learned about conditional probabilities\n",
        "and about one of the most important equations in statistics---Bayes' theorem.\n",
        "It is an effective tool for decoupling information conveyed by data\n",
        "through a likelihood term $P(B \\mid A)$ that addresses\n",
        "how well observations $B$ match a choice of parameters $A$,\n",
        "and a prior probability $P(A)$ which governs how plausible\n",
        "a particular choice of $A$ was in the first place.\n",
        "In particular, we saw how this rule can be applied\n",
        "to assign probabilities to diagnoses,\n",
        "based on the efficacy of the test *and*\n",
        "the prevalence of the disease itself (i.e., our prior).\n",
        "\n",
        "Lastly, we introduced a first set of nontrivial questions\n",
        "about the effect of a specific probability distribution,\n",
        "namely expectations and variances.\n",
        "While there are many more than just linear and quadratic\n",
        "expectations for a probability distribution,\n",
        "these two already provide a good deal of knowledge\n",
        "about the possible behavior of the distribution.\n",
        "For instance, [Chebyshev's inequality](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality)\n",
        "states that $P(|X - \\mu| \\geq k \\sigma) \\leq 1/k^2$,\n",
        "where $\\mu$ is the expectation, $\\sigma^2$ is the variance of the distribution,\n",
        "and $k > 1$ is a confidence parameter of our choosing.\n",
        "It tells us that draws from a distribution lie\n",
        "with at least 50% probability\n",
        "within a $[-\\sqrt{2} \\sigma, \\sqrt{2} \\sigma]$\n",
        "interval centered on the expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Give an example where observing more data can reduce the amount of uncertainty about the outcome to an arbitrarily low level.\n",
        "1. Give an example where observing more data will only reduce the amount of uncertainty up to a point and then no further. Explain why this is the case and where you expect this point to occur.\n",
        "1. We empirically demonstrated convergence to the mean for the toss of a coin. Calculate the variance of the estimate of the probability that we see a head after drawing $n$ samples.\n",
        "    1. How does the variance scale with the number of observations?\n",
        "    1. Use Chebyshev's inequality to bound the deviation from the expectation.\n",
        "    1. How does it relate to the central limit theorem?\n",
        "1. Assume that we draw $m$ samples $x_i$ from a probability distribution with zero mean and unit variance. Compute the averages $z_m \\stackrel{\\textrm{def}}{=} m^{-1} \\sum_{i=1}^m x_i$. Can we apply Chebyshev's inequality for every $z_m$ independently? Why not?\n",
        "1. Given two events with probability $P(\\mathcal{A})$ and $P(\\mathcal{B})$, compute upper and lower bounds on $P(\\mathcal{A} \\cup \\mathcal{B})$ and $P(\\mathcal{A} \\cap \\mathcal{B})$. Hint: graph the situation using a [Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram).\n",
        "1. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? Hint: this is a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "1. In :numref:`subsec_probability_hiv_app`, assume that the outcomes of the two tests are not independent. In particular assume that either test on its own has a false positive rate of 10% and a false negative rate of 1%. That is, assume that $P(D =1 \\mid H=0) = 0.1$ and that $P(D = 0 \\mid H=1) = 0.01$. Moreover, assume that for $H = 1$ (infected) the test outcomes are conditionally independent, i.e., that $P(D_1, D_2 \\mid H=1) = P(D_1 \\mid H=1) P(D_2 \\mid H=1)$ but that for healthy patients the outcomes are coupled via $P(D_1 = D_2 = 1 \\mid H=0) = 0.02$.\n",
        "    1. Work out the joint probability table for $D_1$ and $D_2$, given $H=0$ based on the information you have so far.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after one test returns positive. You can assume the same baseline probability $P(H=1) = 0.0015$ as before.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after both tests return positive.\n",
        "1. Assume that you are an asset manager for an investment bank and you have a choice of stocks $s_i$ to invest in. Your portfolio needs to add up to $1$ with weights $\\alpha_i$ for each stock. The stocks have an average return $\\boldsymbol{\\mu} = E_{\\mathbf{s} \\sim P}[\\mathbf{s}]$ and covariance $\\boldsymbol{\\Sigma} = \\textrm{Cov}_{\\mathbf{s} \\sim P}[\\mathbf{s}]$.\n",
        "    1. Compute the expected return for a given portfolio $\\boldsymbol{\\alpha}$.\n",
        "    1. If you wanted to maximize the return of the portfolio, how should you choose your investment?\n",
        "    1. Compute the *variance* of the portfolio.\n",
        "    1. Formulate an optimization problem of maximizing the return while keeping the variance constrained to an upper bound. This is the Nobel-Prize winning [Markovitz portfolio](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`. To solve it you will need a quadratic programming solver, something way beyond the scope of this book.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "126c2b93",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "126c2b93"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/37)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}